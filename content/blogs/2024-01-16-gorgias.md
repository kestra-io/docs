---
title: "Gorgias — Applying Infrastructure As Code Best Practice to Data Engineering with Kestra"
description: "Dive into how Gorgias employs IaC principles for its data infrastructure using best-of-breed tools, including Kestra, Airbyte, dbt, Hightouch, and Terraform."
date: 2024-01-16T09:00:00
category: Solutions
author:
  name: Benoit Pimpaud
  image: "bpimpaud"
image: /blogs/2024-01-16-gorgias.jpg
---

Infrastructure as Code (IaC) has become the industry standard for cloud resources management and configuration.

It allows teams to easily collaborate across multiple resources through providers and have a common declarative syntax for several purposes: IAM policies, Kubernetes clusters, database users and tables, etc.

What if this same principle were applied to Data Engineering?

That's what [Gorgias](https://www.gorgias.com/) is doing with [Kestra](https://github.com/kestra-io/kestra).

With the rise of the Modern Data Stack, workflows span across diverse tools — ranging from ETL scripts, data transformations, and databases to reverse-ETL processes and ML models.

The current state of solutions involves scattering configurations across various domains:

- **Infrastructure**: service account roles, datasets, Kubernetes clusters
- **Data Sources** (e.g., Segment, SaaS webhooks): Subscribed events, destinations
- **ETL tools** (Airbyte, Fivetran, custom solutions): Sources, destinations, sync frequency, retry policies
- **Transformation** (dbt, sqlmesh, scheduled queries): commands, scheduling, retry policies, monitoring & alerting rules
- **Reverse-ETL** (Hightouch, Census, custom code): Sync schedules, destination configuration

As the number of workflows and data volume increase, Gorgias engineering teams tend to be spinning plates around workflow errors having to maintain complex logic across multiple heterogenous systems.

Embracing framework helps them have a more consistent stack: i.e. using Airbyte for data ingestion enforces writing connectors with a common structure. However, it was not enough to keep data flow logic versioned and maintainable.

Engineering and technical debts start to rise and it is more and more difficult to delegate part of the upstream scope (ingestion, transformation) to Data consumers (Data Analysts, Marketing, HR, Growth teams) as domains are mixed.

In this blog post, we'll dive into how Gorgias employs IaC principles for its data infrastructure using best-of-breed tools, including Kestra, Airbyte, dbt, Hightouch, and Terraform.

## The Control Plane: Data Orchestrator

While internal data analysis often doesn’t necessitate real-time processing, batch processing is optimally managed through orchestration tools, offering the capability to trigger and schedule tasks, much like a cron job.

Yet, some are tempted to consolidate all logic within highly customizable systems like Airflow. Doing ETL, transformation and reverse ETL all with custom code brings some drawbacks:

- Orchestration logic involving complex decorators can present a steep learning curve.
- Intricacies of modularity and deployment strategies, such as building Docker images and creating PyPI packages, add complexity to an already sophisticated process.
- Impact on the entire stack is not always straightforward when implementing changes, especially when updating shared components.

Several months ago, Gorgias faced the limitations of embedded schedulers leading them to the adoption of a dedicated data orchestration tool.

Although many modern data tools integrate schedulers (Hightouch, Dbt cloud, Airbyte, GCP with Cloud Scheduler and scheduled queries), they are not build for handling complex orchestration needs, such as retry policies, event-triggered workflows, and intricate dependencies.

Also, managing numerous execution logs across different tabs further underscored the need for a centralized orchestrator — a main control plane to streamline operations and enhance visibility.


## Declarative Data Orchestration with Kestra

Kestra offers an innovative way to deal with data pipelines based on YAML definition. Fulfilling their need for Infrastructure As Code pattern.
Other important aspects :

- Native integration with all the tools Gorgias is already using: Airbyte, BigQuery, PostgreSQL databases, dbt (CLI and cloud), GitHub, Slack, Hightouch, etc.
- A rich user interface to define tasks and manage flow executions
- Natively support Webhook trigger
- Terraform provider to allows versioning and modularity on top of Flows and thus introduces the best software engineering practices.
- Designed to scale and handle millions of flows in parallel, scaling it is made easy out of the box.
- Full control of data (self-hosted on Kubernetes)
- Easy to contribute to plugins.

With Kestra, the Gorgias team is addressing the following needs:

- Triggering Airbyte sync followed by dbt transformations
- Have proper retry policies. Especially for dbt jobs, as they moved to capacity-based BigQuery pricing they can end up with resource exhaustion issues more often.
- Scheduling Hightouch sync at the end of dbt jobs for better freshness
- Triggering ETL python scripts with easy monitoring based on Webhook events
- Centralized place for all their logs
- Integrated UI allows you to define on-the-fly flows using a nice workflow editor and provide a large collection of blueprints :

![The workflow editor allows to define tasks fully using Kestra UI](/blogs/2024-01-16-gorgias/workflow_editor.png)

![UI provides details for each property available](/blogs/2024-01-16-gorgias/ui-editor.png)

![Blueprints are often good ways to start](/blogs/2024-01-16-gorgias/blueprint.png)

## Modularity with Kestra and Terraform

To provide modular development experience, the Gorgias team leverages Terraform modules and Kestra subflow patterns.

**Modules** are used as an abstraction layer for regular users to write flows (i.e. triggering an Airbyte sync followed by a dbt transformation) without having to worry about Kestra syntax, authentication, or connection details.

**Subflows** are used for generic tasks :
- They contain direct YAML and are declared within subflows/main.tf and define Inputs and Outputs clearly.
- Subflows can depend on each other, this dependency should be materialized by the depends_on field in subflows/main.tf. *Can be used by modules to hide some non-necessary complexity and to dry redundant tasks (Running a SQL query on a given PostgresDB)


![Flow definition to trigger an Airbyte sync and launch dbt command after completion](/blogs/2024-01-16-gorgias/terraform_module_def.png)

Logs are fully streamed from Airbyte to Kestra to provide a centralized platform for monitoring and debugging :

![Flow execution logs](/blogs/2024-01-16-gorgias/airbyte-dbt.png)

## Applying configuration using Kestra as a CI/CD tool

Maintaining a direct connection between external CI / CD tools like GitHub Action to the Kestra server service involves solutions like :
- Creating an ingress exposing the service: it involves using a VPN or an authentication mechanism to secure the system.
- Using port-forward during execution: adds complexity and it is not very standard

To be more efficient, Gorgias's team use Kestra as a CI / CD engine.
As they are applying configuration change on a self-hosted instance, it’s easier to run Terraform directly on their Kubernetes cluster.

With the dedicated Kestra Terraform plugin they can apply changes using the local k8s service endpoint using kube-DNS resolution.
This way, all is handled by Kestra.


![Terraform plan output in execution logs](/blogs/2024-01-16-gorgias/terrafrom_plan_logs.png)

![Topology of the “Terraform plan” flow](/blogs/2024-01-16-gorgias/terraform_topology.png)


## Conclusion

Declarative Data Engineering is rising as Data teams embrace SWE practices and Kestra got this point right allowing data practitioners to collaborate around a common tool.

Join the [Slack community](https://kestra.io/slack) if you have any questions or need assistance. Follow us on [Twitter](https://twitter.com/kestra_io) for the latest news. Check the code in our [GitHub repository](https://github.com/kestra-io/kestra) and give us a star if you like the project.
