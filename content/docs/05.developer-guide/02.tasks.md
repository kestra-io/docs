---
title: Tasks
---

## Runnable Tasks

In Kestra, workloads are executed using **Runnable Tasks**.

Runnable Tasks handle computational work in the flow. For example, file system operations, API calls, database queries, etc. These tasks can be compute-intensive and are handled by [workers](../01.architecture.md#worker).

Each task must have an identifier (id) and a type. The type is the task's Java Fully Qualified Class Name (FQCN).

Tasks have properties specific to the type of the task; check each task's documentation for the list of available properties.

Most available tasks are Runnable Tasks except special ones that are [Flowable Tasks](#flowable-tasks); those are explained later on this page.

By default, Kestra only includes a few Runnable Tasks. However, many of them are available as [plugins](../../plugins/index.md), and if you use our default Docker image, plenty of them will already be included.

### Task common properties

The following task properties can be set.

| Field | Description                                                                                       |
| ---------- |---------------------------------------------------------------------------------------------------|
|`id`| The flow identifier, must be unique inside a flow.                                                |
|`type`| The Java FQCN of the task.                                                                        |
|`description`| The description of the task, more details [here](./01.flow.md#document-your-flow).                |
|`retry`| Task retry behavior, more details [here](./07.errors-handling.md#retries).                        |
|`timeout`| Task timeout expressed in [ISO 8601 Durations](https://en.wikipedia.org/wiki/ISO_8601#Durations). |
|`disabled`| Set it to `true` to disable execution of the task.                                                |
|`workerGroup.key`|To execute this task on a specific [Worker Group (EE)](../01.architecture.md#worker-group-ee).|
|`logLevel`| To define the log level granularity for which logs will be inserted into the backend database. By default, all logs are stored. However, if you restrict that to e.g., the `INFO` level, all lower log levels such as `DEBUG` and TRACE won't be persisted. |
| `allowFailure`    | Boolean flag allowing to continue the execution even if this task fails.                                                                                                                                                                                    |


Task properties can be static or dynamic. Dynamic task properties can be set using [variables](./03.variables/01.index.md). To know if a task property is dynamic, read the task's documentation.


## Flowable Tasks

In Kestra, we orchestrate your workflows using **Flowable Tasks**. These tasks do not compute anything but allow us to build more complex workflows.

Flowable Tasks are used for branching, grouping, doing tasks in parallel, etc...

Flowable Tasks use context [variables](./03.variables/01.index.md) to define the next tasks to run. For example, you can use the [outputs](./05.outputs.md) of a previous task in a `Switch` task to decide which task to run next.

### Sequential

This task processes tasks one after another sequentially. It is used to group tasks.

```yaml
id: sequential
namespace: io.kestra.tests

tasks:
  - id: sequential
    type: io.kestra.core.tasks.flows.Sequential
    tasks:
      - id: 1st
        type: io.kestra.core.tasks.debugs.Return
        format: "{{task.id}} > {{taskrun.startDate}}"
      - id: 2nd
        type: io.kestra.core.tasks.debugs.Return
        format: "{{task.id}} > {{taskrun.id}}"
  - id: last
    type: io.kestra.core.tasks.debugs.Return
    format: "{{task.id}} > {{taskrun.startDate}}"
```

::alert{type="info"}
You can access the output of a sibling task with `{{outputs.sibling.value}}`, see [Lookup in sibling tasks](./05.outputs.md#lookup-in-sibling-tasks)
::

::next-link
[Sequential Task documentation](../../plugins/core/tasks/flows/io.kestra.core.tasks.flows.EachSequential.md)
::


### Parallel

This task processes tasks in parallel. It makes it convenient to process many tasks at once.

```yaml
id: parallel
namespace: io.kestra.tests

tasks:
  - id: parallel
    type: io.kestra.core.tasks.flows.Parallel
    tasks:
      - id: 1st
        type: io.kestra.core.tasks.debugs.Return
        format: "{{task.id}} > {{taskrun.startDate}}"
      - id: 2nd
        type: io.kestra.core.tasks.debugs.Return
        format: "{{task.id}} > {{taskrun.id}}"
  - id: last
    type: io.kestra.core.tasks.debugs.Return
    format: "{{task.id}} > {{taskrun.startDate}}"
```

::alert{type="warning"}
You cannot access the output of a sibling task as tasks will be run in parallel.
::

::next-link
[Parallel Task documentation](../../plugins/core/tasks/flows/io.kestra.core.tasks.flows.Parallel.md)
::

### Switch

This task processes a set of tasks conditionally depending on a contextual variable's value.

In the following example, an input will be used to decide which task to run next.

```yaml
id: switch
namespace: io.kestra.tests

inputs:
  - name: string
    type: STRING
    required: true

tasks:
  - id: switch
    type: io.kestra.core.tasks.flows.Switch
    value: "{{inputs.string}}"
    cases:
      FIRST:
        - id: 1st
          type: io.kestra.core.tasks.debugs.Return
          format: "{{task.id}} > {{taskrun.startDate}}"
      SECOND:
        - id: 2nd
          type: io.kestra.core.tasks.debugs.Return
          format: "{{task.id}} > {{taskrun.startDate}}"
      THIRD:
        - id: 3th
          type: io.kestra.core.tasks.debugs.Return
          format: "{{task.id}} > {{taskrun.startDate}}"
    defaults:
      - id: default
        type: io.kestra.core.tasks.debugs.Return
        format: "{{task.id}} > {{taskrun.startDate}}"
```

::next-link
[Switch Task documentation](../../plugins/core/tasks/flows/io.kestra.core.tasks.flows.Switch.md)
::


### If

This task processes a set of tasks conditionally depending on a condition.
The condition must coerce to a boolean. Boolean coercion allows 0, -0, null and '' to coerce to false,  all other values to coerce to true.
The `else` branch is optional.

In the following example, an input will be used to decide which task to run next.

```yaml
id: if-condition
namespace: io.kestra.tests

inputs:
  - name: param
    type: STRING

tasks:
  - id: if
    type: io.kestra.core.tasks.flows.If
    condition: "{{inputs.param}}"
    then:
      - id: when-true
        type: io.kestra.core.tasks.log.Log
        message: 'Condition was true'
    else:
      - id: when-false
        type: io.kestra.core.tasks.log.Log
        message: 'Condition was false'
```

::next-link
[If Task documentation](../../plugins/core/tasks/flows/io.kestra.core.tasks.flows.If.md)
::


### EachSequential

This task will generate many tasks at runtime depending on the value of a variable.
Each subtask will run after the others sequentially.

In the following example, the variable is static, but it can be generated from a previous task output and starts an arbitrary number of subtasks.

```yaml
id: each
namespace: io.kestra.tests

tasks:
  - id: each
    type: io.kestra.core.tasks.flows.EachSequential
    value: ["value 1", "value 2", "value 3"]
    tasks:
      - id: 1st
        type: io.kestra.core.tasks.debugs.Return
        format: "{{task.id}} > {{taskrun.value}} > {{taskrun.startDate}}"
      - id: 2nd
        type: io.kestra.core.tasks.debugs.Return
        format: "{{task.id}} > {{taskrun.value}} > {{taskrun.startDate}}"
  - id: last
    type: io.kestra.core.tasks.debugs.Return
    format: "{{task.id}} > {{taskrun.startDate}}"
```

::alert{type="info"}
You can access the output of a sibling task with `{{outputs.sibling[taskrun.value].value}}`, see [Lookup in sibling tasks](./05.outputs.md#lookup-in-sibling-tasks)
::


::next-link
[EachSequential Task documentation](../../plugins/core/tasks/flows/io.kestra.core.tasks.flows.EachSequential.md)
::

### EachParallel

This task is the same as EachSequential, but each subtask will run in parallel.

```yaml
id: each-parallel
namespace: io.kestra.tests

tasks:
  - id: 1_each
    type: io.kestra.core.tasks.flows.EachParallel
    value: ["value 1", "value 2", "value 3"]
    tasks:
      - id: 1-1
        type: io.kestra.core.tasks.scripts.Bash
        commands:
          - 'echo "{{task.id}} > $(date +"%T.%N")"'
          - 'sleep 1'
      - id: 1-2
        type: io.kestra.core.tasks.scripts.Bash
        commands:
          - 'echo "{{task.id}} > $(date +"%T.%N")"'
          - 'sleep 1'
  - id: 2_end
    type: io.kestra.core.tasks.debugs.Return
    format: "{{task.id}} > {{taskrun.startDate}}"
```
::alert{type="warning"}
You cannot access the output of a sibling task as tasks will be run in parallel.
::

::next-link
[EachParallel Task documentation](../../plugins/core/tasks/flows/io.kestra.core.tasks.flows.EachParallel.md)
::


### ForEachItem

This task allows you to iterate over a list of items and run a subflow for each item, or for each batch containing multiple items.

Syntax:

```yaml
  - id: each
    type: io.kestra.core.tasks.flows.ForEachItem
    items: "{{ inputs.file }}" # could be also an output variable {{ outputs.extract.uri }}
    inputs:
      file: "{{ taskrun.items }}" # items of the batch
    batch:
      rows: 4
    namespace: dev
    flowId: subflow
    revision: 1 # optional (default: latest)
    wait: true # wait for the subflow execution
    transmitFailed: true # fail the task run if the subflow execution fails
    labels: # optional labels to pass to the subflow to be executed
      key: value
```

This will execute the subflow `dev.subflow` for each batch of items.
To pass the batch of items to a subflow, you can use [inputs](../04.inputs.md). The example above uses an input of `FILE` type called `file` that takes the URI of an internal storage file containing the batch of items.

::next-link
[ForEachItem Task documentation](../../plugins/core/tasks/flows/io.kestra.core.tasks.flows.ForEachItem.md)
::


### DAG

This task allows defining dependencies between tasks by creating a directed acyclic graph (DAG). Instead of an explicit DAG structure, this task allows you to only define upstream dependencies for each task using the `dependsOn` property. This way, you can set dependencies more implicitly for each task, and Kestra will figure out the overall flow structure.

```yaml
id: "dag"
namespace: "io.kestra.tests"
tasks:
  - id: dag
    description: "my task"
    type: io.kestra.core.tasks.flows.Dag
    tasks:
      - task:
          id: task1
          type: io.kestra.core.tasks.log.Log
          message: I'm the task 1
      - task:
          id: task2
          type: io.kestra.core.tasks.log.Log
          message: I'm the task 2
        dependsOn:
          - task1
      - task:
          id: task3
          type: io.kestra.core.tasks.log.Log
          message: I'm the task 3
        dependsOn:
          - task1
      - task:
          id: task4
          type: io.kestra.core.tasks.log.Log
          message: I'm the task 4
        dependsOn:
          - task2
      - task:
          id: task5
          type: io.kestra.core.tasks.log.Log
          message: I'm the task 5
        dependsOn:
          - task4
          - task3
```

::next-link
[Dag Task documentation](../../plugins/core/tasks/flows/io.kestra.core.tasks.flows.Dag.md)
::

### AllowFailure

This task will allow child tasks to fail.
If any child task fails:
- The AllowFailure failed task will be marked as status `WARNING`.
- All children's tasks inside the AllowFailure will be stopped immediately.
- The Execution will continue for all others tasks.
- At the end, the execution as a whole will also be marked as status `WARNING`.

In the following example:
- `allow-failure` will be labelled as `WARNING`.
- `ko` will be labelled as `FAILED`.
- `next` will not be run.
- `end` will be run and labelled `SUCCESS`.

```yaml
id: each
namespace: io.kestra.tests

tasks:
  - id: allow-failure
    type: io.kestra.core.tasks.flows.AllowFailure
    tasks:
      - id: ko
        type: io.kestra.core.tasks.scripts.Bash
        commands:
          - 'exit 1'
      - id: next
        type: io.kestra.core.tasks.debugs.Return
        format: "{{task.id}} > {{taskrun.startDate}}"
  - id: end
    type: io.kestra.core.tasks.debugs.Return
    format: "{{task.id}} > {{taskrun.startDate}}"
```

::next-link
[AllowFailure Task documentation](../../plugins/core/tasks/flows/io.kestra.core.tasks.flows.AllowFailure.md)
::

### Fail

This task will fail the flow; it can be used with or without conditions.

Without conditions, it can be used, for example, to fail on some switch value.

```yaml
id: fail-on-switch
namespace: io.kestra.tests

inputs:
  - name: param
    type: STRING
    required: true

tasks:
  - id: switch
    type: io.kestra.core.tasks.flows.Switch
    value: "{{inputs.param}}"
    cases:
      case1:
        - id: case1
          type: io.kestra.core.tasks.log.Log
          message: Case 1
      case2:
        - id: case2
          type: io.kestra.core.tasks.log.Log
          message: Case 2
      notexist:
        - id: fail
          type: io.kestra.core.tasks.executions.Fail
      default:
        - id: default
          type: io.kestra.core.tasks.log.Log
          message: default
```

With conditions, it can be used, for example, to validate inputs.

```yaml
id: fail-on-condition
namespace: io.kestra.tests

inputs:
  - name: param
    type: STRING
    required: true

tasks:
  - id: before
    type: io.kestra.core.tasks.log.Log
    message: "I'm before the fail on condition"
  - id: fail
    type: io.kestra.core.tasks.executions.Fail
    condition: "{{inputs.param == 'fail'}}"
  - id: after
    type: io.kestra.core.tasks.log.Log
    message: "I'm after the fail on condition"
```


::next-link
[Fail Task documentation](../../plugins/core/tasks/executions/io.kestra.core.tasks.executions.Fail.md)
::


### Flow

This task will trigger another flow.
This allows us to decouple the first flow from the second and monitor each flow individually.

You can pass flow [outputs](./05.outputs.md) as [inputs](./04.inputs.md) for the triggered flow (those must be declared in the sub-flow).

```yaml
id: subflow
namespace: io.kestra.tests

tasks:
  - id: "subflow"
    type: io.kestra.core.tasks.flows.Flow
    namespace: io.kestra.tests
    flowId: my-sub-flows
    inputs:
      file: "{{ inputs.myFile }}"
      store: 12
```

::next-link
[Flow Task documentation](../../plugins/core/tasks/flows/io.kestra.core.tasks.flows.Flow.md)
::


### Worker

The `Worker` task is deprecated in favor of the`WorkingDirectory` task. The next section explains how you can use the`WorkingDirectory` task in order to allow multiple tasks to share a file system during the flow's Execution.

### WorkingDirectory

By default, Kestra will launch each task in a new working directory, possibly on different workers if multiple ones exist.

The example below will run all tasks nested under the `WorkingDirectory` task sequentially. All those tasks will be executed in the same working directory, allowing the reuse of the previous tasks' output files in the downstream tasks. In order to share a working directory, all tasks nested under the `WorkingDirectory` task will be launched on the same worker.

This task can be particularly useful for compute-intensive file system operations.

```yaml
id: working-dir
namespace: io.kestra.tests

tasks:
  - id: working-dir
    type: io.kestra.core.tasks.flows.WorkingDirectory
    tasks:
      - id: first
        type: io.kestra.core.tasks.scripts.Bash
        commands:
          - 'echo "{{ taskrun.id }}" > {{ workingDir }}/stay.txt'
      - id: second
        type: io.kestra.core.tasks.scripts.Bash
        commands:
          - |
            echo '::{"outputs": {"stay":"'$(cat {{ workingDir }}/stay.txt)'"}}::'
```

This task can also cache files inside the working directory, for example, to cache script dependencies like the `node_modules` of a node `Script` task.

```yaml
id: node-with-cache
namespace: io.kestra.tests

tasks:
  - id: working-dir
    type: io.kestra.core.tasks.flows.WorkingDirectory
    cache:
      patterns:
        - node_modules/**
      ttl: PT1H
    tasks:
    - id: script
      type: io.kestra.plugin.scripts.node.Script
      beforeCommands:
        - npm install colors
      script: |
        const colors = require("colors");
        console.log(colors.red("Hello"));
```

This task can also fetch files from [namespace files][namespace files](./namespace-files.md) and make them available to all child tasks.

```yaml
id: node-with-cache
namespace: io.kestra.tests

tasks:
  - id: working-dir
    type: io.kestra.core.tasks.flows.WorkingDirectory
    namespaceFiles:
      enabled: true
      include:
      - dir1/*.*
      exclude:
      - dir2/*.*
    tasks:
    - id: shell
      type: io.kestra.plugin.scripts.shell.Commands
      commands:
      - cat dir1/file1.txt
```

::next-link
[WorkingDirectory Task documentation](../../plugins/core/tasks/flows/io.kestra.core.tasks.flows.WorkingDirectory.md)
::


### Pause

Kestra flows a ran until the end of all tasks, but sometimes, you need to:
- Add a manual validation before continuing the execution.
- Wait for some duration before continuing the execution.

For this, you can use the Pause task.

On the following example, the `validation` will pause until a manual modification of the task step, and the `wait` will wait for 5 minutes.

```yaml
id: pause
namespace: io.kestra.tests

tasks:
  - id: validation
    type: io.kestra.core.tasks.flows.Pause
    tasks:
      - id: ok
        type: io.kestra.core.tasks.scripts.Bash
        commands:
          - 'echo "started after manual validation"'
  - id: wait
    type: io.kestra.core.tasks.flows.Pause
    delay: PT5M
    tasks:
      - id: waited
        type: io.kestra.core.tasks.scripts.Bash
        commands:
          - 'echo "start after 5 minutes"'
```

::alert{type="info"}
A Pause task without delay will wait indefinitely until the task state is changed to **Running**.
For this: go to the **Gantt** tab of the **Execution** page, click on the task, select **Change status** on the contextual menu and select **Mark as RUNNING** on the form. This will make the task run until its end.
::


::next-link
[Pause Task documentation](../../plugins/core/tasks/flows/io.kestra.core.tasks.flows.Pause.md)
::


### Template

[Templates](./09.templates.md) are lists of tasks that can be shared between flows. You can define a template and call it from other flows, allowing them to share a list of tasks and keep these tasks updated without changing your flow.

The following example uses the Template task to use a template.

```yaml
id: template
namespace: io.kestra.tests

tasks:
  - id: template
    type: io.kestra.core.tasks.flows.Template
    namespace: io.kestra.tests
    templateId: template
```


::next-link
[Template Task documentation](../../plugins/core/tasks/flows/io.kestra.core.tasks.flows.Template.md)
::


