---
title: Configuration
icon: /docs/icons/admin.svg
---

Configuration Reference for Kestra.

Almost everything is configurable in Kestra. This section describes the different configuration options available to Administrators.

## Setup

Kestra offers many configuration options and customization. This section will guide you through the most important ones.

The way you pass those configuration options depends on your Kestra installation

::alert{type="warning"}
The configuration is intended to hold deployment-specific options. Using a full copy of the Kestra configuration may break future releases.
::

### Kestra internal components configuration

Kestra has three internal components that need to be configured:

- The Internal Storage.
- The Queue.
- The Repository.

#### Internal storage configuration

Kestra supports multiple internal storage types, the default being the local storage that will store data in a local folder on the host filesystem. It's recommended only for local testing as it doesn't provide resiliency or redundancy.

To choose another storage type, you will need to configure the `kestra.storage.type` option. Make sure to download the corresponding storage plugins first. The following example configures [Google Cloud Storage](#gcs) for internal storage.

```yaml
kestra:
  storage:
    type: gcs
```

Details about storage configuration can be found [here](#kestrastorage).

#### Queue configuration

Kestra supports multiple queue types, the default depends on your [installation](../02.installation/index.md) mode.

The queue type must be compatible with the repository type. Not all combinations are possible.

The following queue types are available:

- In-memory queue used with the in-memory repository — intended for local testing.
- Database queue used with the database repository. It currently supports H2, MySQL, and PostgreSQL as a database.
- Kafka queue used with the Elasticsearch repository. Those are only available in the Enterprise Edition.

To enable the PostgreSQL database queue, you need to add the following to your configuration file:

```yaml
kestra:
  queue:
    type: postgres
```

#### Repository configuration

Kestra supports multiple repository types, the default depends on your [installation](../02.installation/index.md) mode.

The repository type must be compatible with the queue type. Not all combinations are possible.

The following repository types are available:

- In-memory that must be used with the in-memory queue.  It is **only suitable for local testing** as it doesn't provide any resiliency or scalability and didn't implement all functionalities.
- Database that must be used with the database queue. It currently supports H2, MySQL or PostgreSQL as a database.
- Elasticsearch that must be used with the Kafka queue. Those are **only available inside the Enterprise Edition**.

To enable the PostgreSQL database repository, you need to add the following to your configuration files:

```yaml
kestra:
  repository:
    type: postgres
```

For more details, check the [database configuration](#database) and the [Elasticsearch configuration](#kestraelasticsearch).

### Micronaut configuration

Given that Kestra is a Java-based application built on top of Micronaut, there are multiple [Micronaut settings](#micronaut) that you can configure based on your needs.

## Enterprise Edition

Kestra Enterprise Edition offers many enhancements over the Open Source Edition, adding authentication, security, audit logs, and more. Here are some of the features available in the Enterprise Edition:
- [Multi-Tenancy](../06.enterprise/03.tenants.md)
- [Audit Logs](../06.enterprise/06.audit-logs.md)
- [Authentication](../06.enterprise/04.authentication.md)
- [SSO](../06.enterprise/05.sso.md)
- [RBAC](../06.enterprise/rbac.md)
- [Secrets Manager](../06.enterprise/secrets-manager.md)
- [Namespace Management](../06.enterprise/07.namespace-management.md)
- [Worker Groups](../06.enterprise/worker-group.md)
- [Worker Isolation](../06.enterprise/worker-isolation.md)

For more information on what is included in the Enterprise Edition, check out the [product page](/enterprise).

## Database

### `kestra.queue` and `kestra.repository`

First, you need to configure Kestra to use a database for its Queue and Repository. Here is an example for PostgreSQL:

```yaml
kestra:
  queue:
    type: postgres
  repository:
    type: postgres
```

Currently, Kestra supports Postgres, H2, MySQL, and SQL Server (available in a preview in the Enterprise Edition since Kestra 0.18.0).
- H2 can be convenient for local **development**.
- For **production**, we recommend PostgreSQL. If PostgreSQL is not an option for you, MySQL and SQL Server can be used as well.

Check the [Software Requirements](../09.administrator-guide/00.requirements.md) section for the minimum version of each database.

::alert{type="info"}
If you experience performance issues when using PostgreSQL, you can tune the cost optimizer parameter `random_page_cost=1.1`, which should make PostgreSQL use the right index for the queues table. You can also configure `kestra.queue.postgres.disable-seq-scan=true` so that Kestra turns off sequential scans on the queue polling query forcing PostgreSQL to use the index.
::


### Minimal configuration

In order to connect to a database, you need to configure a `datasource`. Kestra uses The [HikariCP](https://github.com/brettwooldridge/HikariCP) connection pool under the hood, and if needed, you can configure multiple options from the HikariCP documentation directly in your datasource configuration.


#### PostgreSQL

Here is a minimal configuration for PostgreSQL:
```yaml
kestra:
  queue:
    type: postgres
  repository:
    type: postgres

datasources:
  postgres:
    url: jdbc:postgresql://localhost:5432/kestra
    driverClassName: org.postgresql.Driver
    username: kestra
    password: k3str4
```

#### MySQL

Here is a minimal configuration for MySQL:
```yaml
kestra:
  queue:
    type: mysql
  repository:
    type: mysql

datasources:
  mysql:
    url: jdbc:mysql://localhost:3306/kestra
    driverClassName: com.mysql.cj.jdbc.Driver
    username: kestra
    password: k3str4
    dialect: MYSQL
```

::alert{type="warning"}
Note that we currently don't support the `8.0.31` version of MySQL. If possible, try another version or reach out via [Slack](/slack) to help you troubleshoot.
::


#### SQL Server

Here is a minimal configuration for a SQL Server database, currently available in preview in the Enterprise Edition since Kestra 0.18.0:

```yaml
kestra:
  repository:
    type: sqlserver
  queue:
    type: sqlserver

datasources:
  sqlserver:
    url: jdbc:sqlserver://localhost:1433
    driverClassName: com.microsoft.sqlserver.jdbc.SQLServerDriver
    username: kestra
    password: k3str4
    dialect: SQL_SERVER
# Uncomment only if your database is not encrypted
#    data-source-properties:
#      encrypt: false
```

::alert{type="warning"}
Note that this feature is currently in preview and only available in the Enterprise Edition. If you want to try it, please [reach out](/demo) to get access.
::

#### H2

Here is a minimal configuration for H2:

```yaml
kestra:
  queue:
    type: h2
  repository:
    type: h2

datasources:
  h2:
    url: jdbc:h2:mem:public;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE
    username: sa
    password: ""
    driverClassName: org.h2.Driver
```

### Connection pool size

The total number of connections opened to the database will depend on your chosen [architecture](../07.architecture/index.md). Each Kestra instance will open a pool of up to the `maximum-pool-size` (10 by default), with a minimum size of the `minimum-idle` (also set to 10 by default).

- If you deploy Kestra as a standalone server, it will open 10 connections to the database.
- If you deploy each Kestra component separately, it will open 40 connections to the database (10 per component).
- If you deploy each Kestra component separately with 3 replicas, it will open 120 connections to the database.

Usually, the default connection pool sizing is enough, as HikariCP is optimized to use a low number of connections.

### `datasources`

Here are the datasource configuration properties. For more details, check the [HikariCP configuration](https://github.com/brettwooldridge/HikariCP#gear-configuration-knobs-baby) documentation:


| Properties                    | Type   | Description                                                                                                                                           |
|-------------------------------|--------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
| `url`                         | String | The JDBC connection string.                                                                                                                       |
| `catalog`                     | String | The default catalog name to be set on connections.                                                                                                 |
| `schema`                      | String | The default schema name to be set on connections.                                                                                                |
| `username`                    | String | The default username used.                                                                                                                        |
| `password`                    | String | The default password to use.                                                                                                                      |
| `transaction-isolation`       | String | The default transaction isolation level.                                                                                                          |
| `pool-name`                   | String | The name of the connection pool.                                                                                                                  |
| `connection-init-sql`         | String | The SQL string that will be executed on all new connections when they are created, before they are added to the pool.                             |
| `connection-test-query`       | String | The SQL query to be executed to test the validity of connections.                                                                                 |
| `connection-timeout`          | Long   | The maximum number of milliseconds that a client will wait for a connection from the pool.                                                        |
| `idle-timeout`                | Long   | The maximum amount of time (in milliseconds) that a connection is allowed to sit idle in the pool.                             |
| `minimum-idle`                | Long   | The minimum number of idle connections that HikariCP tries to maintain in the pool, including both idle and in-use connections. Defaults to the value of `maximum-pool-size` |
| `initialization-fail-timeout` | Long   | The pool initialization failure timeout.                                                                                                          |
| `leak-detection-threshold`    | Long   | The amount of time that a connection can be out of the pool before a message is logged indicating a possible connection leak.  |
| `maximum-pool-size`           | Int    | The maximum size that the pool is allowed to reach, including both idle and in-use connections. Defaults to 10.                                |
| `max-lifetime`                | Long   | The maximum lifetime of a connection in the pool.                                                                              |
| `validation-timeout`          | Long   | The maximum number of milliseconds that the pool will wait for a connection to be validated as alive.                                            |


Here is the default HikariCP configuration:

```yaml
transaction-isolation: default # driver default
pool-name: HikariPool-<Generated>
connection-init-sql: null
connection-test-query: null
connection-timeout: 30000 # 30 seconds
idle-timeout: 600000 # 10 minutes
minimum-idle: 10 # same as maximum-pool-size
initialization-fail-timeout: 1
leak-detection-threshold: 0
maximum-pool-size: 10
max-lifetime: 1800000 # 30 minutes
validation-timeout: 5000
```

### Queues

#### `kestra.jdbc.queues`

Kestra database queues simulate queuing doing long polling. They query a `queues` table to detect new messages.

You can change these parameters to reduce the polling latency, but be aware it will increase the load on the database:

- `kestra.jdbc.queues.poll-size`: the maximum number of queues items fetched by each poll.
- `kestra.jdbc.queues.min-poll-interval`: the minimum duration between 2 polls.
- `kestra.jdbc.queues.max-poll-interval`: the maximum duration between 2 polls.
- `kestra.jdbc.queues.poll-switch-interval`: the delay for switching from min-poll-interval to max-poll-interval when no message is received. (ex: when one message is received, the `min-poll-interval` is used, if no new message arrived within `poll-switch-interval`, we switch to `max-poll-interval`).


Here is the default configuration:

```yaml
kestra:
  jdbc:
    queues:
      poll-size: 100
      min-poll-interval: 25ms
      max-poll-interval: 1000ms
      poll-switch-interval: 5s
```

#### `kestra.jdbc.cleaner`

Kestra cleans the `queues` table periodically to optimize storage and performance. You can control how often you want this cleaning to happen, and how long messages should be kept in the `queues` table .

Here is the default configuration:

```yaml
kestra:
  jdbc:
    cleaner:
      initial-delay: 1h
      fixed-delay: 1h
      retention: 7d
```

#### Protecting against too big messages

::alert{type="info"}
Note: this is an experimental feature available starting with Kestra 0.19.
::

The database backend has no limit on the size of messages it can handle. However, as messages are loaded into memory, this can endanger Kestra itself and push pressure on memory usage.

To prevent that, you can configure a functionality that will refuse to store too big messages and fail the execution instead.

The following configuration will refuse messages that exceed 1MiB by failing the execution.

```yaml
kestra:
  jdbc:
    queues:
      message-protection:
        enabled: true
        limit: 1048576
```

## `kestra.elasticsearch`

**Elasticsearch is an [Enterprise Edition](/enterprise) functionality.**

The most important thing is to configure the way Kestra connects to the Elasticsearch cluster.

Here is a minimal configuration example:

```yaml
kestra:
  elasticsearch:
    client:
      http-hosts: "http://localhost:9200"
  repository:
    type: elasticsearch
```

Here is another example with a secured Elasticsearch cluster with basic authentication:

```yaml
kestra:
  elasticsearch:
    client:
      http-hosts:
        - "http://node-1:9200"
        - "http://node-2:9200"
        - "http://node-3:9200"
      basic-auth:
        username: "<your-user>"
        password: "<your-password>"
  repository:
    type: elasticsearch
```

### `kestra.elasticsearch.client.trust-all-ssl`
Default `false`, if you enable this option, we trust all certificate during connection. Useful for development server with self-signed certificate.

```yaml
kestra:
  elasticsearch:
    client:
      http-hosts: "https://localhost:9200"
      trust-all-ssl: true
```

### `kestra.elasticsearch.defaults.indice-prefix`
This configuration allows to change the indices prefix. By default, the prefix will be `kestra_`.

For example, if you want to share a common Elasticsearch cluster for multiple instances of Kestra, add a different prefix for each instance like this:

```yaml
kestra:
  elasticsearch:
    defaults:
      indice-prefix: "uat_kestra"
```

### `kestra.elasticsearch.indices`
By default, a unique indices is used for all different data, it could be useful to split the index by day / week / month to avoid having large indices in ElasticSearch.

For now, `executions`, `logs` & `metrics` can be split, and we support all this split type:
- `DAILY`
- `WEEKLY`
- `MONTHLY`
- `YEARLY`

```yaml
kestra:
  elasticsearch:
    indices:
      executions:
        alias: daily
      logs:
        alias: daily
      metrics:
        alias: daily
```

#### Index Rotation

When you enable index rotation, it creates an alias and one index per periodicity (day, week, etc.).

It's safe to enable it on an existing instance however the alias will clash with the existing index so you should move the existing index, for example change `kestra_logs` to `kestra_logs-1` before switching to the alias.

As indexes will be created with `name-periodicity` using the `-1` suffix, make sure you will still include the old data (until you make the decision to purge it).

Be careful that not all indexes can be safely purged. You should only enable alias for historical data that keeps growing (like logs, metrics and executions).

It's safe to disable aliases but in the case existing data would not be recovered anymore.

It is totally safe to switch from one periodicity to another as the alias is for `name-*` so the periodicity is not important.

### `kestra.elasticsearch.client.trust-all-ssl`

### `kestra.indexer`
Indexer send data from Kafka to Elasticsearch using Bulk Request. You can control the batch size and frequency to reduce the load on ElasticSearch. This will delay some information on the UI raising that values, example:

```yaml
kestra:
  indexer:
    batch-size: 500 # (default value, any integer > 0)
    batch-duration: PT1S # (default value, any duration)
```

## `kestra.ee.license`

To use Kestra Enterprise Edition, you will need a valid license. Our sales team will provide this license to you; if it's not the case, please reach out to them at [sales@kestra.io](mailto:sales@kstra.io).

The license is set up using two configuration properties: `id` and `key`.

- `kestra.ee.license.id`: license identifier.
- `kestra.ee.license.key`: license key.

When you launch Kestra Enterprise Edition, it will check the license and display the validation step in the log.

### `kestra.encryption`

Kestra 0.15.0 and later supports encryption of sensitive data. This allows inputs and outputs to be automatically encrypted and decrypted when they are stored in the database.

To enable encryption, you need to provide a base64-encoded secret key in the configuration:

```yaml
kestra:
  encryption:
    secret-key: BASE64_ENCODED_STRING_OF_32_CHARCTERS
```

To generate a 32-character string and then base64 encode it, you can use the defacto standard for cryptography, OpenSSL:

```bash
openssl rand -base64 32
```

If you don't have OpenSSL installed, you can use the following Bash commands to generate a base64-encoded 32-character encryption key:

```bash
random_string=$(LC_ALL=C tr -dc 'A-Za-z0-9' < /dev/urandom | head -c 32)
echo "$random_string" | base64
```

If you run Kestra with Docker-Compose, here is how you can add that key in the `KESTRA_CONFIGURATION` environment variable in your `docker-compose.yml` file:

```yaml
  kestra:
    image: kestra/kestra:latest
    environment:
      KESTRA_CONFIGURATION: |
        kestra:
          encryption:
            secret-key: NWRhUDc5TERWY2QyMDhSSHhfeWYzbjJpNE5vb3M5NnY=
```


Once the secret key is set, you can use an `input` and `output` of type `SECRET`:

```yaml
id: my_secret_flow
namespace: company.team

inputs:
  - id: secret
    type: SECRET

tasks:
  - id: mytask
    type: io.kestra.plugin.core.log.Log
    message: task that needs the secret to connect to an external system

outputs:
  - id: secret_output
    type: SECRET
    value: "{{ inputs.secret }}"
```

When executing this flow, you will see a masked field:

![secret1](/docs/configuration-guide/secret1.png)


In the Execution Overview tab, you will see a masked value of the secret.

::alert{type="warning"}
If the `secret-key` is not set in the `kestra.encryption` configuration, you will get an error: `Illegal argument: Unable to use a SECRET input as encryption is not configured` when trying to use a `SECRET` input or output type.
::

## `endpoints`

Management endpoints can be set up from the [Micronaut endpoint configuration](https://docs.micronaut.io/latest/guide/index.html#endpointConfiguration). You can also secure all endpoints with basic authentication using this additional configuration:

```yaml
endpoints:
  all:
    basic-auth:
      username: your-user
      password: your-password
```

## `kestra.environment`

Here are the configuration options for the environment UI display.

You can add a label and a color to identify your environment in the UI by adding this configuration:

```yaml
kestra:
  environment:
    name: Production
    color: "#FCB37C"
```

You can also set that environment name and color directly from the UI. Just go to the settings page and type the desired Environment name and select the color.

![env_color](/docs/administrator-guide/configuration/env_color.png)

## JVM

All JVM options can be passed in an environment variable named `JAVA_OPTS`. You can use it to change all JVM options available, such as memory, encoding, etc.

Example:

```shell
export JAVA_OPTS="-Duser.timezone=Europe/Paris"
```

### `user.timezone`: Timezone
By default, Kestra will handle all dates using your system's timezone. You can change the timezone with JVM options.

Changing the timezone will mostly affect:
* **scheduler**: by default, all schedule dates are UTC; changing the Java timezone will allow scheduling the flow in your timezone.
* **logs display**: in your configured timezone.

## `kestra.kafka`

**Kafka is an [Enterprise Edition](/enterprise) functionality.**

### `kestra.kafka.client.properties`

The most important configuration step is defining how Kestra should connect to the Kafka cluster.

Here is a minimal configuration example:

```yaml
kestra:
  kafka:
    client:
      properties:
        bootstrap.servers: "localhost:9092"
  queue:
    type: kafka
```

Here is another example with SSL configuration:

```yaml
kestra:
  kafka:
    client:
      properties:
        bootstrap.servers: "host:port"
        security.protocol: "SSL"
        ssl.endpoint.identification.algorithm: ""
        ssl.key.password: "<your-password>"
        ssl.keystore.location: "/etc/ssl/private/keystore.p12"
        ssl.keystore.password: "<your-password>"
        ssl.keystore.type: "PKCS12"
        ssl.truststore.location: "/etc/ssl/private/truststore.jks"
        ssl.truststore.password: "<your-password>"
  queue:
    type: kafka
```

`kestra.kafka.client.properties` allows passing any standard Kafka properties. More details can be found [on the Kafka Documentation](https://kafka.apache.org/documentation/).

### `kestra.kafka.defaults.topic`

By default, Kestra automatically creates all the needed topics. You can change the partition count and replication factor of these topics:

- `kestra.kafka.defaults.topic.partitions`: (default 16)
- `kestra.kafka.defaults.topic.replication-factor`: (default 1)

The number of topic's partitions limits the number of concurrently processing server instances consuming that particular topic. For example, using 16 partitions for every topic limits the effective number of instances to 16 executor servers, 16 worker servers, etc.

::alert{type="warning"}
For the optimal value of the replication factor, validate the actual configuration of the target Kafka cluster. Generally, for high availability, the value should match the number of Kafka brokers in the cluster. For example, a cluster consisting of 3 nodes should use the replication factor of 3.
::

### `kestra.kafka.defaults.[consumer|producer|stream].properties`

You can change the default properties of the Kafka client used by Kestra. These allow you to change any available properties.

Here is the default configuration:

```yaml
kestra:
  kafka:
    defaults:
      consumer:
        properties:
          isolation.level: "read_committed"
          auto.offset.reset: "earliest"
          enable.auto.commit: "false"

      producer:
        properties:
          acks: "all"
          compression.type: "lz4"
          max.request.size: "10485760"

      stream:
        properties:
          processing.guarantee: "exactly_once"
          replication.factor: "${kestra.kafka.defaults.topic.replication-factor}"
          acks: "all"
          compression.type: "lz4"
          max.request.size: "10485760"
          state.dir: "/tmp/kafka-streams"
```

### `kestra.kafka.defaults.topics`

All the topics used by Kestra are declared with the default name and properties.
You can change the default values:

- `kestra.kafka.defaults.topics.{{topic}}.name`: Change the name of the topic.
- `kestra.kafka.defaults.topics.{{topic}}.properties`: Change the default properties used during topic automatic creation.

You can see default configuration on this [file](https://github.com/kestra-io/kestra/blob/develop/cli/src/main/resources/application.yml).

### `kestra.kafka.defaults.consumer-prefix`

This configuration allows changing the consumer-group prefix. By default, the prefix will be `kestra`.

For example, if you want to share a common Kafka cluster for multiple instances of Kestra, you must configure a different prefix for each instance like this:

```yaml
kestra:
  kafka:
    defaults:
      consumer-prefix: "uat_kestra"
```

### `kestra.kafka.defaults.topic-prefix`

This configuration allows changing the topic name prefix. By default, the prefix will be `kestra_`.

For example, if you want to share a common Kafka cluster for multiple instances of Kestra, add a different prefix for each instance like this:

```yaml
kestra:
  kafka:
    defaults:
      topic-prefix: "uat_kestra"
```

### `kestra.kafka.client.loggers`

This configuration allows enabling logging for all messages processed by the Kafka cluster. Use it to debug all the messages consumed or produced on the Kafka cluster.

::alert{type="warning"}
This configuration has a huge performance impact, using regexp and serialization for most of the messages.
::

```yaml
kestra:
  kafka:
    client:
      loggers:
        - level: INFO # mandatory: ERROR, WARN, INFO, DEBUG, TRACE, the logger must be configured at least at this level for class io.kestra.runner.kafka.AbstractInterceptor
          type: PRODUCER # optional: CONSUMER or PRODUCER
          topic-regexp: "kestra_(executions|workertaskresult)" # optional: a regexp validating the topic
          key-regexp: .*parallel.* # optional: a regexp validating the key
          value-regexp: .*parallel.* # optional: a regexp validating the json full body
```

### `kestra.kafka.stream.properties.state.dir`

Kestra uses the Kafka Stream framework, this framework uses a local directory for state persistence.
By default, the state directory is `/tmp/kafka-streams` and can be configured using the `kestra.kafka.stream.properties.state.dir` configuration property.

This directory should not be purged while the application runs but can be purged between restarts. If persisted between restarts, the startup time could be improved as the state of the Kafka Stream will be recovered from the directory.

It is advised to purge this directory before a Kestra update, if not, an error message may be displayed in the log that can be safely ignored.

### Topic retention

Each Kafka topic used by Kestra is configurable using the following configuration property:

```yaml
kestra:
  kafka:
    topics:
      execution:
        properties:
          kafka.property: value
```

By default, except for topics where we need unlimited retention as they store referential data like flow or trigger definition, all topics are configured with a default retention of 7 days.

For example, for the topic storing executions, you can configure the retention via this configuration property:

```yaml
  kafka:
    topics:
      execution:
        properties:
          retention.ms: "86400000"
```

### Protecting against too big messages

::alert{type="info"}
Note: this is an experimental feature.
::

Kafka topic has a limit of the size of messages it can handle. By default, we set this limit to 10MiB.
If a message exceeds this limit, it may crash the executor and Kestra will stop.

To prevent that, you can configure a functionality that will automatically store too big messages to the internal storage.

```yaml
kestra:
  kafka:
    message-protection:
      enabled: true
```

The `hard-limit` is not mandatory, in this case messages of any size will be accepted.

## `kestra.listeners`

Listeners are deprecated and disabled by default since the 0.11.0 release. You can re-enable them with this configuration:
```yaml
kestra:
  listeners:
    enabled: true
```

## `logger`

You can change the log behavior in Kestra by adjusting the following configuration parameters:

```yaml
logger:
  levels:
    io.kestra.runner: TRACE
    org.elasticsearch.client: TRACE
    org.elasticsearch.client.sniffer: TRACE
    org.apache.kafka: DEBUG
    io.netty.handler.logging: TRACE
```


### `micronaut.server.netty.access-logger`: Access Log configuration
- `micronaut.server.netty.access-logger.enabled`: enable access log from webserver (default `true`).
- `micronaut.server.netty.access-logger.name`: logger name (default `io.kestra.webserver.access`).
- `micronaut.server.netty.access-logger.format`: access log format (default `"%{yyyy-MM-dd'T'HH:mm:ss.SSS'Z'}t | %r | status: %s | ip: %a | length: %b | duration: %D"`).
- `micronaut.server.netty.access-logger.exclusions`: list of regexp to define which log to exclude.

Here is the default values:

```yaml
micronaut:
  server:
    netty:
      access-logger:
        enabled: true
        name: io.kestra.webserver.access
        format: "[Date: {}] [Duration: {} ms] [Method: {}] [Url: {}] [Status: {}] [Length: {}] [Ip: {}] [Port: {}]"
        exclusions:
          - /ui/.+
          - /health
          - /prometheus
```

### Log Format

We are using [Logback](https://logback.qos.ch/) to handle log. You change the format of the log format, and we provide some default and common one configuring a [logback configuration files](https://logback.qos.ch/manual/).

If you want to customize the log format, you can create a `logback.xml` file and add it to the classpath. Then, add a new `JAVA_OPTS` environment variable: `"-Dlogback.configurationFile=file:/path/to/your/configuration/logback.xml"`

We provide some predefined configuration, and some example of the `logback.xml` files:

#### GCP
```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration debug="false">
    <include resource="logback/base.xml" />
    <include resource="logback/gcp.xml" />

    <root level="WARN">
        <appender-ref ref="CONSOLE_JSON_OUT" />
        <appender-ref ref="CONSOLE_JSON_ERR" />
    </root>
</configuration>
```

#### Elastic Common Schema (ECS) format

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration debug="true">
  <include resource="logback/base.xml" />
  <include resource="logback/ecs.xml" />

  <root level="WARN">
    <appender-ref ref="CONSOLE_ECS_OUT" />
    <appender-ref ref="CONSOLE_ECS_ERR" />
  </root>
</configuration>
```

## `kestra.metrics`

You can set the prefix for all Kestra metrics using the following configuration:

```yaml
kestra:
  metrics:
    prefix: kestra
```

## `micronaut`

As Kestra is a Java-based application built with Micronaut, you can configure any Micronaut configuration options.
We will not explain all the possible configuration options, these are available [here](https://docs.micronaut.io/latest/guide/index.html). However, we will provide some tips on the most useful options:


### Configure port
```yaml
micronaut:
  server:
    port: 8086
```

### Configure SSL
[This guide](https://guides.micronaut.io/latest/micronaut-security-x509-maven-groovy.html) will help you configure SSL with Micronaut. A final working configuration would look as follows (considering you would use environment variables injection for passwords):
```yaml
micronaut:
  security:
    x509:
      enabled: true
  ssl:
    enabled: true
  server:
    ssl:
      client-authentication: need
      key-store:
        path: classpath:ssl/keystore.p12
        password: ${KEYSTORE_PASSWORD}
        type: PKCS12
      trust-store:
        path: classpath:ssl/truststore.jks
        password: ${TRUSTSTORE_PASSWORD}
        type: JKS
```

### Configure the timeout or max uploaded file size
A lot of configuration options affect these, here is the default configuration:
```yaml
micronaut:
  server:
    max-request-size: 10GB
    multipart:
      max-file-size: 10GB
      disk: true
    read-idle-timeout: 60m
    write-idle-timeout: 60m
    idle-timeout: 60m
    netty:
      max-chunk-size: 10MB
```

### Changing base path
If behind a reverse proxy, you can change the base path of the application with the following configuration:
```yaml
micronaut:
  server:
    context-path: "kestra-prd"
```


### Changing host resolution
If behind a reverse proxy, you can change host resolution (http/https/domain name) providing the header sent by your reverse proxy:
```yaml
micronaut:
  server:
    host-resolution:
      host-header: Host
      protocol-header: X-Forwarded-Proto
```


### Configuring CORS
In case you run into issues related to CORS policy, say while calling the webhook API from a JS application, you can enable the processing of CORS requests with the following configuration:
```yaml
micronaut:
  server:
    cors:
      enabled: true
```

For more detailed changes like allowing only specific origins or specific methods, you can refer [this guide](https://docs.micronaut.io/latest/guide/index.html#corsConfiguration).

## `kestra.plugins`

Configuration of Maven repositories used by the command `kestra plugins install`.

Maven Central is mandatory for Kestra and its plugins. However, you can add your own (Maven) repository in order to download your own plugins using the following configuration:

```yaml
kestra:
  plugins:
    repositories:
      central:
        url: https://repo.maven.apache.org/maven2/
      jcenter:
        url: https://jcenter.bintray.com/
      kestra:
        url: https://dl.bintray.com/kestra/maven
```

### Plugin configurations to enable or disable features

The `configuration` of `plugins` section can be also used to enable or disable some features of specific Kestra plugins, or to set some default values for them.

Here is an example of how to enable outputs for `Subflow` and `Flow` tasks:

```yaml
kestra:
  plugins:
    configurations:
      - type: io.kestra.plugin.core.flow.Subflow
        values:
          outputs:
            enabled: true # for backward-compatibility -- false by default
      - type: io.kestra.plugin.core.flow.Flow
        values:
          outputs:
            enabled: true # for backward-compatibility -- false by default
```

By default, the `outputs` property of a parent flow's `Subflow` task is deprecated in favor of flow `outputs` in Kestra 0.15.0 and higher. However, setting such configuration will keep the old behavior with the `outputs` property.

### Plugin configurations to set default values

You can also set default values for a plugin. For example, starting from Kestra 0.15.0, you can set the default value for the `recoverMissedSchedules` property of the `Schedule` trigger to `NONE` to avoid recovering missed scheduled executions after a server restart:

```yaml
kestra:
  plugins:
    configurations:
      - type: io.kestra.plugin.core.trigger.Schedule
        values:
          # Available options: LAST | NONE | ALL. The default is ALL
          recoverMissedSchedules: NONE
```

Before 0.15, Kestra was always recovering missed schedules. This means that if your server was down for a few hours, Kestra would recover all missed schedules when it was back up. This behavior was not always desirable, as often the recovery of missed schedules is not necessary e.g. during a planned maintenance window. This is why, starting from Kestra 0.15 release, you can customize the `recoverMissedSchedules` property and choose whether you want to recover missed schedules or not.

The `recoverMissedSchedules` configuration can be set to `ALL`, `NONE` or `LAST`:
- `ALL`: Kestra will recover all missed schedules. This is the default value.
- `NONE`: Kestra will not recover any missed schedules.
- `LAST`: Kestra will recover only the last missed schedule for each flow.

Note that this is a global configuration that will apply to all flows, unless explicitly overwritten within the flow definition:

```yaml
triggers:
  - id: schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: "*/15 * * * *"
    recoverMissedSchedules: NONE
```

In this example, the `recoverMissedSchedules` is set to `NONE`, which means that Kestra will not recover any missed schedules for this specific flow regardless of the global configuration.

### Restrict which plugins can be used

::alert{type="info"}
This is an [Enterprise Edition](/docs/enterprise) feature available starting with Kestra 0.19.
::

You can restrict which plugins can be used in a Kestra instance by configuring an allowlist / exclude list using regexes.

The following configuration only allow plugin from the `io.kestra` package and disallow the `io.kestra.plugin.core.debug.Echo` plugin.

```yaml
kestra:
  plugins:
    security:
      includes:
        - io.kestra.*
      excludes:
        - io.kestra.plugin.core.debug.Echo
```

### `kestra.plugins.defaults`

You can provide plugin defaults that will be applied to each task on your cluster **if a property is not defined** on flows or tasks. Plugin defaults allow ensuring a property is defined at a default value for these tasks.

```yaml
kestra:
  plugins:
    defaults:
    - type: io.kestra.plugin.core.log.Log
      values:
        level: ERROR
```

Forced plugin defaults ensure a property is set cluster-wise for a task, and no task can override it.
Forced plugin defaults can be handy to enforce security concerns, for example, by enforcing Shell tasks to run as Docker containers.

```yaml
kestra:
  plugins:
    defaults:
      - type: io.kestra.plugin.scripts.shell.Script
        forced: true
        values:
          runner: DOCKER
```

## `kestra.retries`

Kestra uses external storage and secrets so that your private data and secrets are stored in a secure way in your private infrastructure. These external systems communicate with Kestra through APIs. Those API calls, however, might eperience transient failures. To handle these transient failures, Kestra allows you to configure retries.

Here are the available retry configuration options:

- `kestra.retries.attempts`: the max number of retries (default `5`)
- `kestra.retries.delay`: the initial delay between retries (default `1s`)
- `kestra.retries.max-delay`: the max amount of time to retry (default `undefined`)
- `kestra.retries.multiplier`: the multiplier of `delay` between each attempt (default `2.0`)

::alert{type="warning"}
Note that those retries are only applied to API calls made to internal storage (like S3 or GCS) and to secrets managers (like Vault or AWS Secrets Manager). They are not applied to tasks.
::

In order to globally configure retries for tasks, you can use the [plugin defaults](../04.workflow-components/09.plugin-defaults.md) with a global scope tied to the main `io.kestra` plugin path as follows:

```yaml
- type: io.kestra
  retry:
    type: constant # type: string
    interval: PT5M # type: Duration
    maxDuration: PT1H # type: Duration
    maxAttempt: 3 # type: int
    warningOnRetry: true # type: boolean, default is false
```

## `kestra.security`

### `kestra.security.super-admin`

The most powerful user in Kestra is the [SuperAdmin](../06.enterprise/rbac.md#super-admin)

You can create a SuperAdmin user from the configuration file.

The super-admin requires three properties:
* `kestra.security.super-admin.username`: the username of the super-admin
* `kestra.security.super-admin.password`: the password of the super-admin
* `kestra.security.super-admin.tenantAdminAccess`: a list of tenants that the super-admin can access
  * This property can be omitted if you do not use multi-tenancy
  * If a Tenant does not exists, it will be created
  * At each startup, this user is checked and if the list of access permissions has been modified, new access permissions can be created, but none will be removed


::alert{type="warning"}
The password should never be stored in clear text in the configuration file. Make sure to use an environment variable in the format `${KESTRA_SUPERADMIN_PASSWORD}`.
::

```yaml
kestra:
  security:
    super-admin:
      username: your_username
      password: ${KESTRA_SUPERADMIN_PASSWORD}
      tenantAdminAccess:
        - <optional>
```

### `kestra.security.default-role`

The default role is the role that will be assigned to a new user when it is created.

For setup facilities, you can define the default role from the configuration file.
Each time you start Kestra, the default role will be checked and created if it does not exist for every Tenant.

The default role requires three properties:
* `kestra.security.default-role.name`: the name of the default role
* `kestra.security.default-role.description`: the description of the default role
* `kestra.security.default-role.permissions`: the permissions of the default role
  * This has to be a map with a [Permission](../06.enterprise/rbac.md#permissions) as a key and a list of [Action](../06.enterprise/rbac.md#actions) as a value

```yaml
kestra:
  security:
    default-role:
      name: default
      description: "Default role"
      permissions:
        FLOW: ["CREATE", "READ", "UPDATE", "DELETE"]
```

Make sure that you attach the `default-role` configuration under `kestra.security`rather than under `micronaut.security` — it's easy to confuse the two so make sure you enter that configuration in the right place.

::alert{type="info"}
When using [multitenancy](../06.enterprise/03.tenants.md), the default role will be added to every tenant. The admin will then need to explicitly add the user to a tenant.
::

## `kestra.server`

### HTTP Basic Authentication

You can protect your Kestra installation with HTTP Basic Authentication.

```yaml
kestra:
  server:
    basic-auth:
      enabled: true
      username: admin
      password: kestra
```

HTTP Basic Authentication is disabled by default - you can enable it in your Kestra configuration, as shown above. If you need more fine-grained control over user and access management, the Enterprise Edition provides additional authentication mechanisms, including features such as SSO and RBAC. For more details, see
the [Authentication page](../06.enterprise/04.authentication.md).

### Delete configuration files

#### `kestra.configurations.delete-files-on-start`:

This setting allows to delete all configuration files after the server startup. It prevents the ability to read
configuration files (that may contain your secrets) from a Bash task for example. The server will keep these values in
memory, and they won't be accessible from tasks.

::ConfigPropertyCard
---
type: Boolean
defaultValue: false
---
::

### Server Liveness & Heartbeats

Kestra's servers use a heartbeat mechanism to periodically send their current state to the Kestra backend,
indicating their liveness. That mechanism is crucial for the timely detection of server failures and for ensuring
seamless continuity in workflow executions.

Here are the configuration parameters for all server types starting from Kestra **0.16.0**.

Note that although it's recommended to deploy the same configuration for all Kestra servers,
it's perfectly safe to set different values for those parameters depending on the server type.

#### `kestra.server.liveness.enabled`

Enable the liveness probe for the server. This property controls whether a server can be detected as `DISCONNECTED` or
not. Must always be `true` for production environment.

::ConfigPropertyCard
---
type: Boolean
defaultValue: true
---
::

#### `kestra.server.liveness.interval`

Frequency at which an `Executor` will check the liveness of connected servers.

::ConfigPropertyCard
---
type: Duration
defaultValue: 5s
---
::

#### `kestra.server.liveness.timeout`

The time an `Executor` will wait for a state update from a server before considering it as `DISCONNECTED`.

::ConfigPropertyCard
---
type: Duration
defaultValue: 45s
---
::

::alert{type="warning"}
Note that this parameter MUST be configured with the same value for all `Executor` server.
::

#### `kestra.server.liveness.initialDelay`

The initial delay after which an `Executor` will start monitoring the liveliness of a server joining the cluster.

::ConfigPropertyCard
---
type: Duration
defaultValue: 45s
---
::

::alert{type="warning"}
Note that this parameter MUST be configured with the same value for all `Executor` server.
::

#### `kestra.server.liveness.heartbeatInterval`

The interval at which a server will send a heartbeat indicating its current state.
Must be strictly inferior to `kestra.server.liveness.timeout`.

::ConfigPropertyCard
---
type: Duration
defaultValue: 3s
---
::

#### Recommended configuration for production

Here is the default and recommended configuration for production ():

**For JDBC deployment-mode (OSS):**
```yaml
kestra:
  server:
    liveness:
      enabled: true
      interval: 5s
      timeout: 45s
      initialDelay: 45s
      heartbeatInterval: 3s
```

**For Kafka deployment-mode (Enterprise Edition):**
```yaml
kestra:
  server:
    liveness:
      timeout: 1m
      initialDelay: 1m
```

::alert{type="warning"}
Note that Worker liveness is directly managed by the Apache Kafka protocol which natively provides
durability and reliability of task executions.
::

::collapse{title="For Kestra versions prior to 0.16.0"}


Prior to Kestra 0.16.0, the liveness mechanism was only supported by **Workers** ([JDBC deployment mode](../07.architecture/index.md#architecture-with-jdbc-backend)).
A **Worker** was either `UP` or `DEAD`. `Executors` was responsible to detect unhealthy workers as follows:

* If the last received Heartbeat for a `Worker` is older than `heartbeat-missed * frequency`, then the `Worker` is
  marked as unhealthy.
* If the last received Heartbeat for a `Worker` is older than `heartbeat-missed * frequency * 2`, then the `Worker` is
  deleted from the server metadata.
::

### `kestra.heartbeat.frequency`

The interval at which a Worker will send a heartbeat indicating its current state.

::ConfigPropertyCard
---
type: Duration
defaultValue: 10s
---
::

### `kestra.heartbeat.heartbeat-missed`

The number of missed heartbeats before `Executors` will consider a Worker as `DEAD`.

::ConfigPropertyCard
---
type: Integer
defaultValue: 3
---
::

### Worker Task Restart Strategy

Starting with Kestra `0.16.0`, you can configure the strategy to be used by `Executors` when a `Worker` is
detected as unhealthy regarding uncompleted tasks ([JDBC deployment mode](../07.architecture/index.md#architecture-with-jdbc-backend)).

#### `kestra.server.workerTaskRestartStrategy`

The strategy to be used for restarting uncompleted tasks in the event of a worker failure.

Supported strategies are:

* **`NEVER`**:

Tasks will never be restarted in the event of a worker failure (i.e., tasks are run at most once).

* **`IMMEDIATELY`**:

Tasks will be restarted immediately in the event of a worker failure, (i.e., as soon as a worker is detected
as `DISCONNECTED`).
This strategy can be used to reduce task recovery times at the risk of introducing duplicate executions (i.e., tasks are
run at least once).

* **`AFTER_TERMINATION_GRACE_PERIOD`**:

Tasks will be restarted on worker failure after the `kestra.server.terminationGracePeriod`.
This strategy should prefer to reduce the risk of task duplication  (i.e., tasks are run exactly once in the best
effort).


::ConfigPropertyCard
---
type: String
defaultValue: AFTER_TERMINATION_GRACE_PERIOD
validValues: NEVER, IMMEDIATELY, AFTER_TERMINATION_GRACE_PERIOD
---
::

### Termination Grace Period

When a Kestra Server receives a `SIGTERM` signal it will immediately try to stop gracefully.

Starting with Kestra `0.16.0`, you can configure the termination grace period for each Kestra Server.
The termination grace period defines the allowed period for a server to stop gracefully.

#### `kestra.server.terminationGracePeriod`

The expected time for the server to complete all its tasks before shutting down.

::ConfigPropertyCard
---
type: Duration
defaultValue: 5m
---
::

## `kestra.storage`

The default [internal storage](../07.architecture/09.internal-storage.md) implementation is the local storage which is **not suitable for production** as it will store data in a local folder on the host filesystem.

This local storage can be configured as follows:

```yaml
kestra:
  storage:
    type: local
    local:
      base-path: /tmp/kestra/storage/ # your custom path
```

Other internal storage types include:
- [Storage S3](#s3) for [AWS S3](https://aws.amazon.com/s3/)
- [Storage GCS](#gcs) for [Google Cloud Storage](https://cloud.google.com/storage)
- [Storage Minio](#minio) compatible with  others *S3 like* storage services
- [Storage Azure](#azure) for [Azure Blob Storage](https://azure.microsoft.com/en-us/services/storage/blobs/)

### S3

First, make sure that the S3 storage plugin is installed in your environment. You can install it with the following Kestra command:
`./kestra plugins install io.kestra.storage:storage-s3:LATEST`. This command will download the plugin's jar file into the plugin's directory.

Then, enable the storage using the following configuration:

```yaml
kestra:
  storage:
    type: s3
    s3:
      endpoint: "<your-s3-endpoint>" # Only needed if you host your own S3 storage
      accessKey: "<your-aws-access-key-id>"
      secretKey: "<your-aws-secret-access-key>"
      region: "<your-aws-region>"
      bucket: "<your-s3-bucket-name>"
      forcePathStyle: "<true|false>" # optional, defaults to false, useful if you mandate domain resolution to be path-based due to DNS for eg.
```

If you are using an AWS EC2 or EKS instance, you can use the default credentials provider chain. In this case, you can omit the `accessKey` and `secretKey` options:

```yaml
kestra:
  storage:
    type: s3
    s3:
      region: "<your-aws-region>"
      bucket: "<your-s3-bucket-name>"
```

Additional configurations can be found [here](https://github.com/kestra-io/storage-s3/blob/master/src/main/java/io/kestra/storage/s3/S3Storage.java#L52-L75).


::collapse{title="Assume IAM Role - AWS Security Token Service (STS)"}

You can configure Amazon S3 storage to utilize **AWS AssumeRole** to temporarily assume the permissions of a specific **IAM** role.
When using AssumeRole with S3, you can omit specifying the `AccessKeyId` and `SecretAccessKey` in your configurations.
Instead, the _default credentials provider chain_ will be used to authenticate with AWS STS and retrieve the temporary security credentials.

```yaml
kestra:
  storage:
    type: s3
    s3:
      region: "<your-aws-region>"
      bucket: "<your-s3-bucket-name>"
      stsRoleArn: "<ARN of the role to assume>"
      # (Optional)
      stsRoleExternalId: "<AWS STS External Id>"
      # (Optional, Default: 'kestra-storage-s3-<timestamp>')
      stsRoleSessionName: "<AWS STS Session name>"
      # (Optional, Default: 15m)
      stsRoleSessionDuration: "<AWS STS Session duration>"
      # (Optional)
      stsEndpointOverride: "<AWS Endpoint to communicate with>"
```
::

### Minio

If you use Minio or similar S3-compatible storage options, you can follow the same process as shown above to install the Minio storage plugin. Then, make sure to include the Minio's `endpoint` and `port` in the storage configuration:

```yaml
kestra:
  storage:
    type: minio
    minio:
      endpoint: "<your-endpoint>"
      port: "<your-port>"
      accessKey: "<your-accessKey>"
      secretKey: "<your-secretKey>"
      region: "<your-region>"
      secure: "<your-secure>"
      bucket: "<your-bucket>"
      partSize: "<your-part-size>" # syntax: <number><unit> (KB, MB, GB), defaults to 5MB
```

Optionally and if the Minio configured is configured to do so (`MINIO_DOMAIN=my.domain.com` environment variable on Minio server), you can also use the `kestra.storage.minio.vhost: true` property to make Minio client to use the [virtual host syntax](https://min.io/docs/minio/linux/administration/object-management.html#id1).

Please note that the endpoint should always be your base domain (even if you use the virtual host syntax). In the above example, `endpoint: my.domain.com`, `bucket: my-bucket`. Setting `endpoint: my-bucket.my.domain.com` will lead to failure.

### Azure

First, install the Azure storage plugin. To do that, you can leverage the following Kestra command:
`./kestra plugins install io.kestra.storage:storage-azure:LATEST`. This command will download the plugin's jar file into the plugins directory.

Adjust the storage configuration shown below depending on your chosen authentication method:

```yaml
kestra:
  storage:
    type: azure
    azure:
      endpoint: "https://unittestkt.blob.core.windows.net"
      container: storage
      connectionString: "<connection-string>"
      sharedKeyAccountName: "<shared-key-account-name>"
      sharedKeyAccountAccessKey: "<shared-key-account-access-key>"
      sasToken: "<sas-token>"
```

::alert{type="info"}
Note that your Azure Blob Storage should disable `Hierarchical namespace` as this feature is [not supported](https://github.com/kestra-io/plugin-azure/issues/22) in Kestra.
::

### GCS

You can install the GCS storage plugin using the following Kestra command:
`./kestra plugins install io.kestra.storage:storage-gcs:LATEST`. This command will download the plugin's jar file into the plugins directory.

Then, you can enable the storage using the following configuration:

```yaml
kestra:
  storage:
    type: gcs
    gcs:
      bucket: "<your-bucket-name>"
      project-id: "<project-id or use default projectId>"
      serviceAccount: "<serviceAccount key as JSON or use default credentials>"
```

If you haven't configured the `kestra.storage.gcs.serviceAccount` option, Kestra will use the default service account, which is:
- the service account defined on the cluster (for GKE deployments)
- the service account defined on the compute instance (for GCE deployments).

You can also provide the environment variable `GOOGLE_APPLICATION_CREDENTIALS` with a path to a JSON file containing GCP service account key.

You can find more details in the [GCP documentation](https://cloud.google.com/docs/authentication/production).

## `kestra.system-flows`

By default, the `system` namespace is reserved for [System Flows](../05.concepts/system-flows.md). These background workflows are intended to perform routine tasks such as sending alerts and purging old logs. If you want to overwrite the name used for System Flows, use the following configuration:

```yaml
kestra:
  system-flows:
    namespace: system
```

## `kestra.tasks`

### `kestra.tasks.scripts.docker.volume-enabled`

Volumes mount are disabled by default for security reasons, you can enabled it with this configurations:

```yaml
kestra:
  tasks:
    scripts:
      docker:
        volume-enabled: true
```

### Temporary storage configuration
Kestra writes temporary files during task processing. By default, files will be created on `/tmp`, but you can change the location with this configuration:

```yaml
kestra:
  tasks:
    tmp-dir:
      path: /home/kestra/tmp
```

**Note:** The `tmp-dir` path must be aligned to the volume path otherwise Kestra will not know what directory to mount for the `tmp` directory. 
```yaml
volumes:
  - kestra-data:/app/storage
  - /var/run/docker.sock:/var/run/docker.sock
  - /home/kestra:/home/kestra
```
In this example, `/home/kestra:/home/kestra` matches the tasks `tmp-dir` field.

### `kestra.tutorial-flows`

Tutorial flows are used to help users understand how Kestra works. They are used in the Guided Tour that allows you to select your use case and see how Kestra can help you solve it.

#### Disable Tutorial Flows

To disable the tutorial flows, set the `tutorial-flows` property to `false` in your configuration file.

```yaml
kestra:
  tutorial-flows:
    enabled: false # true by default
```

The tutorial flows are included in the open-source edition of Kestra by default. It's recommended to set that property to `false` in production environments to avoid unnecessary flows from being loaded into the production system.

## `kestra.templates`
Templates are marked as [deprecated](../11.migration-guide/0.11.0/templates.md) and disabled by default starting from the 0.11.0 release. You can re-enable them with this configuration:

```yaml
kestra:
  templates:
    enabled: true
```

## `kestra.variables`

### `kestra.variables.env-vars-prefix`

Kestra provides a way to use environment variables in your flow. By default, Kestra will only look at environment variables that start with `KESTRA_`. You can change this prefix by setting the `env-vars-prefix` configuration option:

```yaml
kestra:
  variables:
    env-vars-prefix: KESTRA_
```

These variables will be accessible in a flow with `{{ envs.your_env }}` in **lowercase without the prefix**.

For example, an environment variable with the name `KESTRA_MY_ENV` can be accessed using `{{ envs.my_env }}`.

### `kestra.variables.globals`

You can also set global variables directly in the configuration file. These variables will be accessible in all flows across the instance.

For example, the following variable will be accessible in a flow using `{{ globals.host }}`:

```yaml
kestra:
  variables:
    globals:
      host: pg.db.prod
```

Keep in mind that if a variable is in camel case, it will be transformed into hyphenated case. For example, the global variable shown below will be accessible in flows with `{{ globals['my-var'] }}` or `{{ globals['environment-name'] }}`:

```yaml
kestra:
  variables:
    globals:
      environment_name: dev
      myVar: my variable
```

### `kestra.variables.recursive-rendering`

Flag enabling the pre-0.14.0 [template recursive rendering](../11.migration-guide/0.14.0/recursive-rendering.md) behavior and giving administrators more time to migrate deployed flows. Defaults to `false`.

### `kestra.variables.cache-enabled`

The rendering of template variables can be CPU intensive, and by default we **enable** a cache of "templates". You can disable it, even though it's recommended keeping it enabled.

### `kestra.variables.cache-size`

The rendering of template variables cache is an LRU cache (keeps most commonly used variables) and will be cached in memory (default `1000`). You can change the size of the template cache (in number of templates) using this configuration. Keep in mind that the higher this number will be, the more memory the server will use.


## `kestra.webserver`

### `kestra.webserver.google-analytics`: Google Analytics ID
Add Google Analytics tracking ID (ex: `UA-12345678-1`) and report all page tracking.


### `kestra.webserver.html-head`: Append HTML tags to the webserver application
Useful for injecting CSS or JavaScript to customize a web application.

For example, here is how you can add a red banner in production environments:
```yaml
kestra:
  webserver:
    html-head: |
      <style type="text/css">
        .v-sidebar-menu .logo:after {
          background: var(--danger);
          display: block;
          content: "Local";
          position: relative;
          text-transform: uppercase;
          bottom: -65px;
          text-align: center;
          color: var(--white-always);
        }
      </style>
```
