---
title: Deployment Architecture
---


Kestra is a Java application that is provided as an executable. You have many deployments options:
- [Docker](../09.administrator-guide/02.deployment/01.docker.md)
- [Kubernetes](../09.administrator-guide/02.deployment/02.kubernetes.md)
- [Manual deployment](../09.administrator-guide/02.deployment/03.manual.md)

At its heart, Kestra has a plugin system allowing you to choose the dependency type that fits your needs.

You can find three example deployment architectures below.

## Small-sized deployment

![Kestra Standalone Architecture](/docs/architecture/archi-diagram-small.jpg "Kestra Standalone Architecture")

For a small-sized deployment, you can use Kestra standalone server, an all-in-one server component that allows running all Kestra server components in a single process. This deployment architecture has no scaling capability.

In this case, a database is the only dependency. This allows running Kestra with a minimal stack to maintain. We have, for now, three databases available:
- PostgreSQL
- MySQL
- H2

Database configuration options are available [here](../09.administrator-guide/01.configuration/01.databases.md).


## Medium-sized deployment

![Kestra Architecture](/docs/architecture/archi-diagram-medium-sized-deployement.jpg "Kestra Architecture")

For a medium-sized deployment, where high availability is not a strict requirement, you can use a database (Postgres or MySQL) as the only dependency. This allows running Kestra with a minimal stack to maintain. We have, for now, two databases available for this kind of architecture, as H2 is not a good fit when running distributed components:
- PostgreSQL
- MySQL

All server components will communicate through the database.

::alert{type="warning"}
When using a database, you can't scale the replica count for the scheduler, and you must have only **one** instance of it for the whole cluster.
::

Database configuration options are available [here](../09.administrator-guide/01.configuration/01.databases.md).

In this deployment mode, unless all components run on the same host, you must use a distributed storage implementation like Google Cloud Storage, AWS S3, or Azure Blob Storage.

## High-availability deployment

![Kestra High Availability Architecture](/docs/architecture/archi-diagram.jpg "Kestra High Availability Architecture")

To support higher throughput, and full horizontal and vertical scaling of the Kestra cluster, we can replace the database with Kafka and Elasticsearch. In this case, all the server components can be scaled without any single point of failure.

Kafka and Elasticsearch are available only in the **[Enterprise Edition](/enterprise)**.

In this deployment mode, unless all components run on the same host, you must use a distributed storage implementation like Google Cloud Storage, AWS S3, or Azure Blob Storage.

### Kafka

[Kafka](https://kafka.apache.org/) is Kestra's primary dependency in high availability mode. Each of the most important server components in the deployment must have a Kafka instance up and running. Kafka allows Kestra to be a highly scalable solution.

Kafka configuration options are available [here](../09.administrator-guide/01.configuration/03.enterprise-edition/kafka.md).

#### Kafka Executor

With Kafka, the Executor is a heavy [Kafka Stream](https://kafka.apache.org/documentation/streams/) application. The Executor processes all events from Kafka in the right order, keeps an internal state of the execution, and merges task run results from the Worker.
It also detects dead Workers and resubmits the tasks run by a dead Worker.

As the Executor is a Kafka Stream, it can be scaled as needed (within the limits of partitions count on Kafka). Still, as no heavy computations are done in the Executor, this server component only requires a few resources (unless you have a very high rate of executions).

#### Kafka Worker

With Kafka, the Worker is a [Kafka Consumer](https://kafka.apache.org/documentation/#consumerapi) that will process any Task Run submitted to it. Workers will receive all tasks and dispatch them internally in their Thread Pool.

It can be scaled as needed (within the limits of partitions count on Kafka) and have many instances on multiple servers, each with its own Thread Pool.

With Kafka, if a Worker is dead, the Executor will detect it and resubmit their current task run to another Worker.

### Elasticsearch
[Elasticsearch](https://www.elastic.co/) is Kestra's User Interface database in high availability mode, allowing the display, search, and aggregation of all Kestra's data (Flows, Executions, etc.). Elasticsearch is only used by the Webserver (API and UI).

Elasticsearch configuration options are available [here](../09.administrator-guide/01.configuration/03.enterprise-edition/elasticsearch.md).
