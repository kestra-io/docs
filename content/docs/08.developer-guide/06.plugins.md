---
title: Build a Custom Plugin
icon: /docs/icons/dev.svg
---

Browse [Kestra's integrations](/plugins) and learn how to create your own plugins.

## The purpose of plugins

Plugins are the building blocks of Kestra's tasks and triggers. They encompass components interacting with external systems and performing the actual work in your flows.

Kestra comes prepackaged with hundreds of [plugins](/plugins), and you can also develop your own custom plugins.

To integrate with your internal systems and processes, you can build custom plugins. If you think it could be useful to others, consider contributing your plugin to our open-source community.

## Setup for Plugin Development

### Plugin Template
To get started with building a new plugin, make sure to use the [plugin-template](https://github.com/kestra-io/plugin-template), as it comes prepackaged with the standardized repository structure and deployment workflows.

That template will create a project hosting a group of plugins — we usually create multiple subplugins for a given service. For example, there's only one plugin for AWS, but it includes many subplugins for specific AWS services.

::alert{type="warning"}
Note that the Kestra plugin library **version** must align with your Kestra instance. You may encounter validation issues during flow creation (e.g. `Invalid bean` response with status 422) when some plugins are on an older version of the Kestra plugin library. In that case, you may want to update the file `plugin-yourplugin/gradle.properties` and set the `version` property to the correct Kestra version e.g.:

```
version=0.18.0-SNAPSHOT
kestraVersion=[0.18,)
```

It's not mandatory that your plugin version matches the Kestra version, Kestra's official plugins version will always match the minor version of Kestra but it's only a best practice.

Then rebuild and publish the plugin.
::

#### Requirements
Kestra plugins development requirements are:
* [Java](https://java.com) 21 or later.
* [IntelliJ IDEA](https://www.jetbrains.com/idea/) (or any other Java IDE, we provide only help for IntelliJ IDEA).
* [Gradle](https://gradle.org/) (included most of the time with the IDE).


#### Create a new plugin

Here are the steps:

1. Go to the [plugin-template](https://github.com/kestra-io/plugin-template) repository.
2. Click on *Use this template*.
3. Choose the GitHub account you want to link and the repository name for the new plugin.
4. Clone the new repository: `git clone git@github.com:{{user}}/{{name}}.git`.
5. Open the cloned directory in IntelliJ IDEA.
6. Enable [annotations processors](https://www.jetbrains.com/help/idea/annotation-processors-support.html).
7. If you are using an IntelliJ IDEA < 2020.03, install the [lombok plugins](https://plugins.jetbrains.com/plugin/6317-lombok) (if not, it's included by default).


Once you completed the steps above, you should see a similar directory structure:

![Structure](/docs/plugin-developer-guide/plugins-architecture.png)

As you can see, there is one generated plugin: the `Example` class representing the `Example` plugin (a task).

A project typically hosts multiple plugins. We call a project a group of plugins, and you can have multiple sub-groups inside a project by splitting plugins into different packages. Each package that has a plugin class is a sub-group of plugins.

### Plugin icons

Plugin icons need to be added in the SVG format — see an example [here in the JIRA plugin](https://github.com/kestra-io/plugin-jira/commit/64393190281c9001eb8f57b412a0d7d74f986d41).

**Where can you find icons?**
- for proprietary systems, Wikipedia is a good source of SVG icons
- for AWS services, the [AWS icons](https://awsicons.dev/) is a great resource
- [Google Fonts Icons](https://fonts.google.com/icons)
- [Feather Icons](https://feathericons.com/).


## Gradle Configuration
We use [Gradle](https://gradle.org/) as a build tool. This page will help you configure Gradle for your plugin.

### Mandatory configuration
The first thing you need to configure is the plugin name and the class package.

1. Change in `settings.gradle` the `rootProject.name = 'plugin-template'` with your plugin name.
2. Change the class package: by default, the template provides a package `io.kestra.plugin.templates`, just rename the folder in `src/main/java` & `src/test/java`
3. Change the package name on `build.gradle`: replace `group "io.kestra.plugin.templates"` to the package name.


Now you can start [developing your task](#develop-a-task) or look at other optional gradle configurations.

### Other configurations

#### Include some dependencies on plugins

You can add as many dependencies to your plugins, they will be isolated in the Kestra runtime. Thanks to this isolation, we ensure that two different versions of the same library will not clash and have runtime errors about missing methods.

The `build.gradle` handle most of Kestra use case by default using `compileOnly "io.kestra:core"` for Kestra libs.

But if your plugin need some dependencies, you can add as many as you want that will be isolated, you just need to add `api` dependencies:

```groovy
api group: 'com.google.code.gson', name: 'gson', version: '2.8.6'
```

## Develop a Task
Here are the instructions for developing a new task.

There are multiple kinds of tasks that Kestra can execute:
- **Runnable tasks**: executed on the Worker, implement `RunnableTask`. Allow the implementation of a workflow step: computation, technology integration (database, external service), API call, ...
- **Flowable tasks**: executed on the Executor, implement `FlowableTask`. Allow the implementation orchestration logic.
- **Executable tasks**: executed on the Executor, implement `ExecutableTask`. Allow the creation of executions of a flow (the same or a different), what is called a sub-flow.
- **Execution updatable tasks**: executed on the Executor, implement `ExecutionUpdatableTask`. Allow the update of the current execution.

Except for very specific needs, you usually need to implement custom runnable tasks.

### Runnable tasks

::collapse{title="Here is a simple Runnable Task that reverses a string"}

```java
@SuperBuilder
@ToString
@EqualsAndHashCode
@Getter
@NoArgsConstructor
@Schema(
    title = "Reverse a string",
    description = "Reverse all letters from a string"
)
@Plugin
public class ReverseString extends Task implements RunnableTask<ReverseString.Output> {
    @Schema(
        title = "The base string you want to reverse"
    )
    @PluginProperty(dynamic = true)
    private String format;

    @Override
    public ReverseString.Output run(RunContext runContext) throws Exception {
        Logger logger = runContext.logger();

        String render = runContext.render(format);
        logger.debug(render);

        return Output.builder()
            .reverse(StringUtils.reverse(render))
            .build();
    }

    @Builder
    @Getter
    public static class Output implements io.kestra.core.models.tasks.Output {
        @Schema(
            title = "The reverse string "
        )
        private final String reverse;
    }
}
```
::

Let's look at this one more deeply:

#### Class annotations
```java
@SuperBuilder
@ToString
@EqualsAndHashCode
@Getter
@NoArgsConstructor
@Schema(
    title = "Reverse a string",
    description = "Reverse all letters from a string"
)
@Plugin
```
These are required to make your plugin work with Kestra.

The first four annotations are [Lombok](https://projectlombok.org/) annotations that allow Kestra and its internal serialization to work properly.

The `@Schema` is not mandatory per se but is a must have to document your plugin, it is a standard [OpenAPI](https://www.openapis.org/) annotation.

The `@Plugin` is the most important annotation that defines that the class is a plugin, it can contains example to add to the generated documentation. This annotation will be use by the Kestra annotation for plugin discovery.


#### Class declaration
```java
public class ReverseString extends Task implements RunnableTask<ReverseString.Output>
```

* `ReverseString` is the name of your task, and it can be used on Kestra with `type: io.kestra.plugin.templates.ReverseString` (aka: `{{package}}.{{className}}`).
* Class tasks must extend `Task`.
* Runnable tasks must implement `RunnableTask` with a type parameter being the output of the task, here `ReverseString.Output`. If the task has no output you can use the `VoidOutput` type and return null.

#### Properties
```java
@PluginProperty(dynamic = true)
private String format;
```
Declare all the properties you can pass to the current task in a flow. For example, this will be a valid YAML for this task:

```yaml
type: io.kestra.plugin.templates.ReverseString
format: "{{ outputs.previousTask.name }}"
```

You can declare as many properties as you want. All of these will be filled by Kestra executors.

You can use any serializable by [Jackson](https://github.com/FasterXML/jackson) types for your properties (ex: Double, boolean, ...). You can create any class as long as the class is serializable.

##### Properties validation
Properties can be validated using `javax.validation.constraints.*` annotations. When the user creates a flow, your task properties will be validated before insertion and prevent wrong definition to be inserted.

The default available annotations are:
- `@Positive`
- `@AssertFalse`
- `@AssertTrue`
- `@Max`
- `@Min`
- `@Negative`
- `@NegativeOrZero`
- `@Positive`
- `@PositiveOrZero`
- `@NotBlank`
- `@NotNull`
- `@Null`
- `@NotEmpty`
- `@Past`
- `@PastOrPresent`
- `@Future`
- `@FutureOrPresent`

You can also create your own custom validation. You must define the annotation as follows:

```java
@Retention(RetentionPolicy.RUNTIME)
@Constraint(validatedBy = RegexValidator.class)
@Target({ METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE })
public @interface Regex {
    String message() default "invalid pattern ({validatedValue})";
    Class<?>[] groups() default {};
    Class<? extends Payload>[] payload() default {};
}
```

You must also define a validator class that implements the validation logic:

```java
@Singleton
@Introspected
public class RegexValidator implements ConstraintValidator<Regex, String> {
    @Override
    public boolean isValid(
        @Nullable String value,
        @NonNull AnnotationValue<Regex> annotationMetadata,
        @NonNull ConstraintValidatorContext context) {
        if (value == null) {
            return true;
        }

        try {
            Pattern.compile(value);
        } catch (PatternSyntaxException e) {
            context.disableDefaultConstraintViolation();
            context.buildConstraintViolationWithTemplate("invalid pattern [" + value + "]")
                .addConstraintViolation();
            return false;
        }

        return true;
    }
}
```


#### Run method

```java
@Override
public ReverseString.Output run(RunContext runContext) throws Exception {
    Logger logger = runContext.logger();

    String render = runContext.render(format);
    logger.debug(render);

    return Output.builder()
        .reverse(StringUtils.reverse(render))
        .build();
}
```
The `run` method contains the main logic of your task. It will be called by the Worker to execute your task.

You can add any Java code here with any required libraries as long as you have declared them in the [Gradle configuration](#gradle-configuration).

##### Log

```java
Logger logger = runContext.logger();
```

Logging must be done using the run context logger. This will provide a logger for the current execution that creates log events integrated into Kestra and displayed in the UI. Don't create your own logger, or even worse, use `System.out`!


##### Render variables

```java
String render = runContext.render(format);
```
To use dynamic expressions, you need to render them i.e. transform the properties with Pebble.
Don't forget to render variables if you must pass an output from previous variables.

You also need to add the annotation `@PluginProperty(dynamic = true)` to explain in the documentation that you can pass some dynamic variables.
Provide a `@PluginProperty` annotation even if you didn't set any of its attributes for all variables or the generated documentation will not be accurate.

##### Kestra's internal storage

To access Kestra's internal storage, you must use `runContext.storage()`.

You can read any files from Kestra's internal storage using the method `runContext.storage().getFile(URI uri)`.

```java
final URI from = new URI(runContext.render(this.from));
final InputStream inputStream = runContext.storage().getFile(from);
```

You will get an `InputStream` that allows reading the file from Kestra's internal storage (coming from flow inputs or task outputs).

You can also write files to Kestra's internal storage using `runContext.storage().putFile(File file)` or `runContext.storage().putFile(InputStream is)`.

When using `putFile` with a `File`, the file will be deleted after uploading to the internal storage, so you must use a temporary file.

For creating temporary files, you must use `runContext.workingDir()` to be sure the file will be created inside the tak's working directory. All methods on this interface protect against path traversal which is important for security reasons and can be enforced in the Enterprise Edition using [Java Security](https://kestra.io/docs/enterprise/worker-isolation#java-security).

```java
Path tempFile = runContext.workingDir().createTempFile("Hello World".getBytes(), ".txt");
URI output = runContext.storage().putFile(tempFile.toFile())
```

The `URI` returned by the `putFile()` method must be added to the task outputs so it can be used by other tasks and accessed from the UI.


#### Outputs

```java
public class ReverseString extends Task implements RunnableTask<ReverseString.Output> {
    @Override
    public ReverseString.Output run(RunContext runContext) throws Exception {
        return Output.builder()
            .reverse(StringUtils.reverse(render))
            .build();
    }

    @Builder
    @Getter
    public static class Output implements io.kestra.core.models.tasks.Output {
        @Schema(
            title = "The reversed string"
        )
        private final String reverse;
    }
}
```

Each tasks must return a class instance with output values that can be used in the following tasks.
You must return a class that implements `io.kestra.core.models.tasks.Output`.
You can add as many properties as you want, just keep in mind that outputs need to be serializable. At execution time, outputs can be accessed by downstream tasks by leveraging outputs expressions e.g. `{{ outputs.task_id.output_attribute }}`.


If your task doesn't provide any outputs (mostly never), you can use `io.kestra.core.models.tasks.VoidOutput`:
```java
public class NoOutput extends Task implements FlowableTask<VoidOutput> {
    @Override
    public VoidOutput run(RunContext runContext) throws Exception {
        return null;
    }
}
```

#### Exception

In the `run` method, you can throw any `Exception` that will be caught by Kestra and will fail the execution.
We advise you to throw any Exception that can fail your task as soon as possible.

#### Metrics

You can expose metrics to add observability to your task. Metrics will be recorded with the execution and can be accessed via the UI or as [Prometheus metrics](/docs/administrator-guide/monitoring/prometheus).

There are two kinds of metrics available:

- `Counter`: `Counter.of("your.counter", count, tags);` with arguments
  - `String name`: The name of the metric
  - `Double|Long|Integer|Float count`: the associated counter value
  - `String... tags`: a list of tags associated with the metric
- `Timer`: `Timer.of("your.duration", duration, tags);`
  - `String name`: The name of the metric
  - `Duration duration`: the recorded duration
  - `String... tags`: a list of tags associated with the metric

To save metrics with the execution, you must use `runContext.metric(metric)`.

##### Name

Must be lowercase separated by dots.

##### Tags

Must be pairs of tag key and value. An example of two valid tags (`zone` and `location`) is:

```java
Counter.of("your.counter", count, "zone", "EU", "location", "France");
```

#### Documentation

To document your task and its properties and outputs, we provide a set of annotations explained in the [Document each plugin](/docs/developer-guide/documentation) section.


#### Other

There are a lot of other things you can do in a runnable task thanks to the run context:
- Access the [Key Value (KV) store](https://kestra.io/docs/concepts/kv-store) of the namespace using `runContext.namespaceKv()`.
- Access flow and execution information and variables using `runContext.flowInfo()` and `runContext.getVariables()`.
- Encrypt and decrypt properties or outputs using `runContext.encrypt()` and `runContext.decrypt()`.
- Access plugin configuration using `runContext.pluginConfiguration(String name)`.
- Access to [Namespace Files](https://kestra.io/docs/developer-guide/namespace-files) of the namespace using `runContext.storage().namespace()` or of another namespace using `runContext.storage().namespace(String namespace)`.
- Use the [State Store](https://kestra.io/docs/developer-guide/storage#storing-data-inside-the-state-store) or implement caching using various methods on `runContext.storage()`.


### Flowable tasks

[Flowable tasks](/docs/concepts/flowable-tasks) are the most complex tasks to implement and will usually be available from the Kestra core. You will rarely need to create a flowable task by yourself.

::alert{type="warning"}
When developing such task, you must make it fault-tolerant, as an exception thrown by a flowable task can endanger the Kestra instance and lead to inconsistencies in the flow execution.
::

Keep in mind that a flowable task will be evaluated very frequently inside the Executor and must have low CPU usage; no I/O should be done by this kind of task.

Flowable tasks must implement a set of methods to:
- Provide error management.
- Compute the next tasks to execute.
- Provide a graph to display in the topology.

We will use as an example the [Sequential](https://kestra.io/plugins/core/tasks/flow/io.kestra.plugin.core.flow.sequential) task which is a task that will execute a set of tasks, sequentialy. 
We will not go into details as flowable task implementation is complex. To go deeper, you can look a the various flowable tasks we provide [here](https://github.com/kestra-io/kestra/tree/develop/core/src/main/java/io/kestra/plugin/core/flow).

::collapse{title="Flowable task example"}
```java
// <1>
@SuperBuilder
@ToString
@EqualsAndHashCode
@Getter
@NoArgsConstructor
@Schema(
    title = "Run tasks sequentially, one after the other, in the order they are defined.",
    description = "Used to visually group tasks."
)
@Plugin()
public class Sequential extends Task implements FlowableTask<VoidOutput> { // <2>
    // <3>
    @Valid
    protected List<Task> errors;

    // <4>
    @Valid
    @PluginProperty
    private List<Task> tasks;

    // <5>
    @Override
    public AbstractGraph tasksTree(Execution execution, TaskRun taskRun, List<String> parentValues) throws IllegalVariableEvaluationException {
        GraphCluster subGraph = new GraphCluster(this, taskRun, parentValues, RelationType.SEQUENTIAL);

        GraphUtils.sequential(
            subGraph,
            this.getTasks(),
            this.errors,
            taskRun,
            execution
        );

        return subGraph;
    }

    // <6>
    @Override
    public List<Task> allChildTasks() {
        return Stream
            .concat(
                this.getTasks() != null ? this.getTasks().stream() : Stream.empty(),
                this.getErrors() != null ? this.getErrors().stream() : Stream.empty()
            )
            .toList();
    }

    // <7>
    @Override
    public List<ResolvedTask> childTasks(RunContext runContext, TaskRun parentTaskRun) throws IllegalVariableEvaluationException {
        return FlowableUtils.resolveTasks(this.getTasks(), parentTaskRun);
    }

    // <8>
    @Override
    public List<NextTaskRun> resolveNexts(RunContext runContext, Execution execution, TaskRun parentTaskRun) throws IllegalVariableEvaluationException {
        return FlowableUtils.resolveSequentialNexts(
            execution,
            this.childTasks(runContext, parentTaskRun),
            FlowableUtils.resolveTasks(this.getErrors(), parentTaskRun),
            parentTaskRun
        );
    }
}
```
::

1. Flowable tasks annotations are the same as for a runnable task.
2. Flowable tasks extend `Task` as for all tasks and implement `FlowableTask<Output>`, as a sequential task didn't produce any output we use `VoidOutput`.
3. The `errors` property is the list of tasks to execute in case of errors on any of the sub-tasks.
4. The `tasks` property is the list of sub-tasks to execute.
5. The `tasksTree()` method creates the graph to be displayed in the flow and execution topology views. Here we create a sequential graph with the list of sub-tasks and error tasks.
6. The `allChildTasks()` method returns the list of all tasks, including errors.
7. The `childTasks()` method returns the resolved tasks for a given parent task run.
8. The `resolveNexts()` method returns the next tasks to run for a given execution and parent task run. This is the most important method that will be called by the executor to know which task should be executed next. Here it will return the next task to run using the list of errors or sub-tasks.

### Executable task

You can use as an example the [Subflow](https://kestra.io/plugins/core/tasks/flow/io.kestra.plugin.core.flow.subflow) task [here](https://github.com/kestra-io/kestra/blob/develop/core/src/main/java/io/kestra/plugin/core/flow/Subflow.java).

### Execution Updatable task

You can use as an example the [Labels](https://kestra.io/plugins/core/tasks/execution/io.kestra.plugin.core.execution.labels) task [here](https://github.com/kestra-io/kestra/blob/develop/core/src/main/java/io/kestra/plugin/core/execution/Labels.java).

### Unit test

We use JUnit as our testing framework.

To test a task, you will create a unit test as you would for any other Java classes.

::collapse{title="Unit test of the Example task"}
```java
@KestraTest // <1>
class ExampleTest {
    // <2>
    @Inject
    private RunContextFactory runContextFactory;

    @Test
    void run() throws Exception {
        // <3>
        RunContext runContext = runContextFactory.of(ImmutableMap.of("variable", "John Doe"));

        // <4>
        Example task = Example.builder()
            .format("Hello {{ variable }}")
            .build();

        // <5>
        Example.Output runOutput = task.run(runContext);

        // <6>
        assertThat(runOutput.getChild().getValue(), is(StringUtils.reverse("Hello John Doe")));
    }
}
```
::

1. The `@KestraTest` will make sure all needed Kestra components are started before your test.
2. This is a standard Micronaut test so injection is possible. We inject the `RunContextFactory` to be able to create a test run context.
3. Creation of the run context, we add a variable at creation time to mock a previous task output variable so it s available for the task we test.
4. Creation of the task using it's builder. All needed properties need to be set.
5. Task execution.
6. Test assertion using the output of the task.
 
## Develop a Trigger

There are two kinds of [triggers](/docs/workflow-components/triggers) that can be developed:
- **Polling triggers**: poll an external system at a fixed rate for the presence of data and start an execution with the events (micro-batch).
- **Reatime triggers**: react to events as they happen with millisecond latency and start one execution by event.

Kestra comes with other kinds of triggers (like Schedule or Webhook), but those needs adhoc code inside the Kestra core to work so you cannot implement these kinds of triggers from a custom plugin.

### Polling triggers

::collapse{title="The Trigger example below will create an execution randomly"}

```java
// <1>
@SuperBuilder
@ToString
@EqualsAndHashCode
@Getter
@NoArgsConstructor
@Plugin
@Schema(
    title = "Trigger an execution randomly",
    description ="Trigger an execution randomly"
)
public class Trigger extends AbstractTrigger implements PollingTriggerInterface, TriggerOutput<Trigger.Output> { // <2>
    // <3>
    @Builder.Default
    private final Duration interval = Duration.ofSeconds(60);

    // <4>
    protected Double min = 0.5;

    // <5>
    @Override
    public Optional<Execution> evaluate(ConditionContext conditionContext, TriggerContext context) {
        double random = Math.random();
        if (random < this.min) {
            return Optional.empty();
        }

        RunContext runContext = conditionContext.getRunContext();
        runContext.logger().info("Will create an execution");
        Execution execution = TriggerService.generateExecution(
            this, 
            conditionContext, 
            context, 
            Trigger.Output.builder().random(random).build()
        );

        return Optional.of(execution);
    }

    // <6>
    @Builder
    @Getter
    public static class Output implements io.kestra.core.models.tasks.Output {
        private Double random;
    }
}
```
::

1. Polling triggers annotations are the same as for tasks
2. Polling triggers extend `AbstractTrigger` and implements `PollingTriggerInterface` and `TriggerOutput<Output`. Here the output is of type `Trigger.Output` but you can use `VoidOutput` if your trigger didn't procude any outputs.
3. Polling triggers must have an `interval` property that will be the polling periodicity. It is advised to set a default with a not too low value such as 1 minute. Kestra's Scheduler will use this property to decide whether the trigger needs to be evaluated or not.
4. Polling triggers can have multiple properties such as tasks.
5. The `evaluate()` method is the main entry point for a polling trigger, it will be called by the Worker and can return an execution is evaluation is successful or an empty optional. The run context can be retrieved using `conditionContext.getRunContext()`.
6. Polling triggers can have output properties that will be available for the triggered execution.

::alert{type="warning"}
Take care that the trigger must frees their resources before the next evaluation. For each interval, this method will be called and if the conditions are met, an execution will be created.

To avoid this, move the file or remove the record from the database; take an action to avoid an infinite triggering.
::

### Realtime triggers

Realtime triggers are more complex to implement as they must create a reactive stream of executions that will be consumed by the Worker.

You can find an example for the [Kafka](https://kestra.io/plugins/plugin-kafka/triggers/io.kestra.plugin.kafka.realtimetrigger) realtime trigger [here](https://github.com/kestra-io/plugin-kafka/blob/master/src/main/java/io/kestra/plugin/kafka/RealtimeTrigger.java).

### Documentation

To document your triggers, we provide a set of annotations explained in the [Document each plugin](#document-your-plugin) section.

### Unit test

Triggers are usually not tested using a unit test but a [flow test](#testing-a-plugin-using-a-flow). However it is possible to create a test the same way we create a [test for a task](#unit-test).

## Develop a condition

Conditions are used by the Scheduler to determine when a specific trigger should create a new execution.

Here is how you can develop a new [Condition](/docs/workflow-components/triggers#conditions.md).


::collapse{title="Here is a simple condition example that validates the current flow:"}
```java
// <1>
@SuperBuilder
@ToString
@EqualsAndHashCode
@Getter
@NoArgsConstructor
@Schema(
    title = "Condition for a specific flow"
)
@Plugin(
    examples = {
        @Example(
            full = true,
            code = {
                "- conditions:",
                "    - type: io.kestra.plugin.core.condition.ExecutionFlowCondition",
                "      namespace: company.team",
                "      flowId: my-current-flow"
            }
        )
    }
)
public class ExecutionFlowCondition extends Condition { // <2>
    // <3>
    @NotNull
    @Schema(title = "The namespace of the flow")
    public String namespace;

    @NotNull
    @Schema(title = "The flow ID")
    public String flowId;

    // <4>
    @Override
    public boolean test(ConditionContext conditionContext) {
        return conditionContext.getFlow().getNamespace().equals(this.namespace) && conditionContext.getFlow().getId().equals(this.flowId);
    }
}
```
::

1. Conditions annotations are the same as for tasks.
2. Conditions extend `Condition`.
3. Conditions can have multiple properties such as tasks.
4. The `test()` method is the main entry point for a condition, it returns a boolean to `true` if the condition is met. The `conditionContext` provides information about the evaluated exeuction and give access to the run context via the `conditionContext.runContext()` method.


### Documentation

To document your conditions, we provide a set of annotations explained in the [Document each plugin](#document-each-plugin) section.

### Unit test

Unit testing a condition is very close to unit testing a task. As for testing a condition you need a flow and an execution, there is a `TestsUtils` to create mocks of them.

::collapse{title="Here is an example of a condition test:"}
```java
@KestraTest
class ExecutionFlowConditionTest {
    @Inject
    ConditionService conditionService;

    @Test
    void valid() {
        Flow flow = TestsUtils.mockFlow();
        Execution execution = TestsUtils.mockExecution(flow, ImmutableMap.of());

        ExecutionFlowCondition build = ExecutionFlowCondition.builder()
            .namespace(flow.getNamespace())
            .flowId(flow.getId())
            .build();

        boolean test = conditionService.isValid(build, flow, execution);

        assertThat(test, is(true));
    }

    @Test
    void notValid() {
        // ...
    }
}
```
::

## Develop a task runner

Task Runners is an extensible, pluggable system capable of executing your tasks in arbitrary remote environments.

::collapse{title="Example of a task runner inspired by the Process task runner:"}
```java
// <1>
@SuperBuilder
@ToString
@EqualsAndHashCode
@Getter
@NoArgsConstructor
@Schema(
    title = "Task runner that executes a task as a subprocess on the Kestra host.",
    description = "Task runner that executes a task as a subprocess on the Kestra host.")
@Plugin
public class Process extends TaskRunner { //<2>

    // <3>
    @Override
    public RunnerResult run(RunContext runContext, TaskCommands taskCommands, List<String> filesToDownload) throws Exception {
        Logger logger = runContext.logger();
        AbstractLogConsumer defaultLogConsumer = taskCommands.getLogConsumer();

        java.lang.ProcessBuilder processBuilder = new java.lang.ProcessBuilder();

        processBuilder.directory(taskCommands.getWorkingDirectory().toFile());
        processBuilder.command(taskCommands.getCommands());

        java.lang.Process process = processBuilder.start();
        long pid = process.pid();
        logger.debug("Starting command with pid {} [{}]", pid, String.join(" ", taskCommands.getCommands()));


        try {
            int exitCode = process.waitFor();

            if (exitCode != 0) {
                throw new TaskException(exitCode, defaultLogConsumer.getStdOutCount(), defaultLogConsumer.getStdErrCount());
            } else {
                logger.debug("Command succeed with code {}", exitCode);
            }

            return new RunnerResult(exitCode, defaultLogConsumer);
        } catch (InterruptedException e) {
            logger.warn("Killing process {} for InterruptedException", pid);
            killDescendantsOf(process.toHandle(), logger);
            process.destroy();
            throw e;
        } 
    }
}
```
::

1. Task runners annotations are the same as for tasks.
2. Task runners extend `TaskRunner`. They can have multiple properties such as tasks, but none exist here.
3. The `run()` methods is the main entry point of a task runner. It will run the task commands, gather logs and outputs and return a `RunnerResult`. Here it will run the command as sub-process of the Kestra process, this is a simplified example, the real code can be found [here](https://github.com/kestra-io/kestra/blob/develop/core/src/main/java/io/kestra/plugin/core/runner/Process.java). This method is called by the Worker for tasks that can run inside a task runner (scripts and CLI tasks for example).

### Documentation

To document your task runner, we provide a set of annotations explained in the [Document each plugin](#document-each-plugin) section.

### Unit test

Testing a task runner is really easy (but developing one is very complex) as we provide an abstract test with a suite of tests that cover all the task runner functionalities.

For examle, for the Process task runner:

```java
class ProcessTest extends AbstractTaskRunnerTest {

    @Override
    protected TaskRunner taskRunner() {
        return new Process();
    }
}
```

## Testing a plugin using a flow

In case you want to add a test with a flow, for example to test a trigger or a flowable task, you can do it by creating a flow YAML definition and launching it using the standalone runner with an embedded H2 database.

::collapse{title="Example of a flow test"}
```java
@KestraTest
class ExampleRunnerTest {
    // <1>
    @Inject
    protected StandAloneRunner runner;

    // <2>
    @Inject
    protected RunnerUtils runnerUtils;

    // <3>
    @Inject
    protected LocalFlowRepositoryLoader repositoryLoader;

    // <4>
    @BeforeEach
    private void init() throws IOException, URISyntaxException {
        repositoryLoader.load(Objects.requireNonNull(ExampleRunnerTest.class.getClassLoader().getResource("flows")));
        this.runner.run();
    }

    @SuppressWarnings("unchecked")
    @Test
    void flow() throws TimeoutException {
        // <5>
        Execution execution = runnerUtils.runOne(null, "io.kestra.templates", "example");

        assertThat(execution.getTaskRunList(), hasSize(3));
        assertThat(((Map<String, Object>)execution.getTaskRunList().get(2).getOutputs().get("child")).get("value"), is("task-id"));
    }
}
```
::

1. You will need an instance of the `StandAloneRunner` to run Kestra.
2. You will need an instance of the `RunnerUtils` to execute a flow.
3. You will need an instance of the `LocalFlowRepositoryLoader` to load your flow YALM.
4. The `init()` will be called before each tests, and will load the flow YAML definitions from the `flows` directory (inside `src/main/resources`). Then, it will start Kestra in standalone mode with an embedded H2 database.
5. Use the `runnerUtils.runOne(tenantId, namespace, flowId)` method to execute your flow, it will return an execution on which you can make assertions.


To make it work, you need to have an `application.yml` file with this minimum configuration:

```yaml
kestra:
  repository:
    type: memory
  queue:
    type: memory
  storage:
    type: local
    local:
      base-path: /tmp/unittest
```

And these dependencies on your `build.gradle`:
```groovy
testImplementation "io.kestra:repository-memory"
testImplementation "io.kestra:runner-memory"
testImplementation "io.kestra:storage-local"
```

Both are already set into the plugin template.


## Document Your Plugin
Here is how you can document your plugin.

First, let us remember the organization of a plugin project:

- The Gradle project can contain several plugins, we call it a group of plugins.
- The package in which a plugin is written in is called a sub-group of plugins. Sometimes, there is only one sub-group, in which case the group and the sub-group are the same.
- Each class is a plugin that provides one task, trigger, condition, etc.

The plugin documentation will be used on the Kestra website and the Kestra UI.

We provide a way to document each level of a plugin project.

### Document the plugin group

#### Manifest attributes

Kestra uses custom manifest attributes to provide top-level group documentation.

The following manifest attributes are used to document the group of plugins:

- `X-Kestra-Title`: by default, the Gradle `project.name` property is used.
- `X-Kestra-Group`: by default, the Gradle `group.id` property with an additional group name is used.
- `X-Kestra-Description`: by default, the Gradle `project.description` property is used.
- `X-Kestra-Version`: by default, the Gradle `project.version` property is used.

If you follow the plugin structure of the template on GitHub, you should have something like this:
::collapse{title="Example"}

```groovy
group "io.kestra.plugin"
description 'Google Cloud Platform (GCP) plugins for Kestra.'

// [...]

jar {
    manifest {
        attributes(
                "X-Kestra-Title": project.name,
                "X-Kestra-Group": project.group + ".gcp",
                "X-Kestra-Description": project.description,
                "X-Kestra-Version": project.version
        )
    }
}
```
::

As you can see, the most important documentation attribute is the `description`, which should be a short sentence describing the plugins.

#### Additional markdown files

You can add additional markdown files in the `src/main/resources/doc` directory.

If there is a file `src/main/resources/doc/<plugin-group>.md`, it will be inlined inside the main documentation page as the long description for the group of plugins.

For example, for the GCP group of plugins, the file is `src/main/resources/doc/io.kestra.plugin.gcp.md`, and it contains authentication information that applies to all tasks.

If there are files inside the `src/main/resources/doc/guides` directory, we will list them in a `Guides` section on the documentation for the group of plugins.

#### Group Icon

It is possible to provide an icon representing the whole plugin group. If there is a [SVG file](https://www.w3.org/Graphics/SVG/) `src/main/resources/icons/plugin-icon.svg`, it will be used as the group icon.

### Document the plugin sub-groups

Each sub-group can be documented via the `io.kestra.core.models.annotations.PluginSubGroup` annotation that must be defined at the package level in a `package-info.java` file.

The `@PluginSubGroup` annotation allows setting:

- The sub-group `title`. If not set, the name of the sub-group will be used.
- The sub-group `description`, which is a short sentence introducing the sub-group.
- The sub-group `categories`, which is a list of `PluginCategory`. If not set, the category `MISC` will be used.

For example, for the GCP BigQuery sub-group:

```java
@PluginSubGroup(
    title = "BigQuery",
    description = "This sub-group of plugins contains tasks for accessing Google Cloud BigQuery.\n" +
        "BigQuery is a completely serverless and cost-effective enterprise data warehouse.",
    categories = { PluginSubGroup.PluginCategory.DATABASE, PluginSubGroup.PluginCategory.CLOUD }
)
package io.kestra.plugin.gcp.bigquery;

import io.kestra.core.models.annotations.PluginSubGroup;
```

#### Sub-Group Icon

Each plugin sub-group can define an icon representing plugins contained in the sub-group. If there is a SVG file `src/main/resources/icons/<plugin-sub-group>.svg`, it will be used as the icon for the corresponding plugins.

For example, for the GCP BigQuery sub-group, the `src/main/resources/icons/io.kestra.plugin.gcp.bigquery.svg` file is used.

### Document each plugin

Plugin documentation will generate a [JSON Schema](https://json-schema.org/) that will be used to validate flows. It also generates documentation for both the UI and the website (see the `kestra plugins doc` command).

#### Document the plugin class

Each plugin class must be documented via the following:

- The `io.kestra.core.models.annotations.Plugin` annotation allows providing examples.
- The `io.swagger.v3.oas.annotations.media.Schema` annotation, which the `title` attribute will use as the plugin description.

For example, the `Query` task of the PostgreSQL group of plugins is documented as follows:

```java
@Schema(
    title = "Query a PostgresSQL server"
)
@Plugin(
    examples = {
        @Example(
            full = true,
            title = "Execute a query",
            code = {
                "tasks:",
                "- id: update",
                "  type: io.kestra.plugin.jdbc.postgresql.Query",
                "  url: jdbc:postgresql://127.0.0.1:56982/",
                "  username: postgres",
                "  password: pg_passwd",
                "  sql: select concert_id, available, a, b, c, d, play_time, library_record, floatn_test, double_test, real_test, numeric_test, date_type, time_type, timez_type, timestamp_type, timestampz_type, interval_type, pay_by_quarter, schedule, json_type, blob_type from pgsql_types",
                "  fetch: true"}
        )
    }
)
```

For convenience, the `code` attribute of the `@Example` annotation is a list of strings. Each string will be a line of the example. That avoids concatenating multi-line strings in a single attribute.

But now that Java supports multi-line string, you are better of using a single multi-line string instead.

You can add multiple examples if needed.

#### Document the plugin properties

In a plugin, all properties must be annotated by `io.kestra.core.models.annotations.PluginProperty` and should provide documentation via the `io.swagger.v3.oas.annotations.media.Schema` annotation and validation rules via `javax.validation.constraints.*`.

The `@PluginProperty` annotation contains two attributes:

- `dynamic`: set it to true if the property will be rendered dynamically.
- `additionalProperties`: you can use it to denote the sub-type of the property. For example, when using a `Map<String, Message>`, you can set it to `Message.class`.

The Swagger `@Schema` annotation contains a lot of attributes that can be used to document the plugin properties. The most useful are:

- `title`: a short description of a property.
- `description`: long description of a property.
- `anyOf`: a list of allowed sub-types of a property. Use it when the property type is an interface, an abstract class, or a class inside a hierarchy of classes to denote possible sub-types. This should be set when the property type is `Object`.

The `@Schema` and `@PluginProperty` annotations can be used on fields, methods, or classes.

Many tasks can take input from multiple sources on the same property. They usually have a single `from` property, a string representing a file in the Kestra Storage, a single object, or a list of objects. To document such property, you can use `anyOf` this way:

```java
@PluginProperty(dynamic = true)
@NotNull
@Schema(
    title = "The source of the published data.",
    description = "Can be an internal storage URI, a list of Pub/Sub messages, or a single Pub/Sub message.",
    anyOf = {String.class, Message[].class, Message.class}
)
private Object from;
```

::alert{type="info"}
Due to limitations on how JSON Schema works, you cannot add `@Schema` on a Java enum type and the plugin property that uses this type. We advise avoiding using `@Schema` on enumerations.
::

### Document the plugin outputs

Outputs should be documented with the `io.swagger.v3.oas.annotations.media.Schema` annotation in the same way as plugin properties. Please read the section above for more information.

Only use the annotation mentioned above. Never use `@PluginProperty` on an output.

### Document the plugin metrics

Tasks can expose metrics; to document those you must add a `@Metric` annotation instance for each metric in the `@Plugin` annotation instance of the task.

For example, to document two metrics: a **length** metric of type `counter` and a **duration** metric of `type` timer, you can use the following:

```java
@Plugin(
    metrics = {
        @Metric(name = "length", type = Counter.TYPE),
        @Metric(name = "duration", type = Timer.TYPE)
    }
)
```


## Build and Publish a Plugin
Use the included Gradle task to build the plugin. Then, you can publish it to [Maven Central](https://central.sonatype.com).

### Build a plugin
To build your plugin, execute the `./gradlew shadowJar` command from the plugin directory.

The resulting JAR file will be generated in the `build/libs` directory.

To use this plugin in your Kestra instance, add this JAR to the [Kestra plugins path](/docs/administrator-guide/server-cli#plugins-directory).

#### Use a custom docker image with your plugin

Adding this `Dockerfile` to the root of your plugin project:
```
FROM kestra/kestra:develop

COPY build/libs/* /app/plugins/
```
You can build and run the image with the following command assuming you're in the root directory of your plugin:
`./gradlew shadowJar && docker build -t kestra-custom . && docker run --rm -p 8080:8080 kestra-custom server local`

You can now navigate to http://localhost:8080 and start using your custom plugin. Feel free to adapt the Dockerfile to your needs (eg. if you plan to use multiple custom plugins, include all builds directory in it).

### Publish a plugin

Here is how you can publish your plugin to Maven Central.

#### GitHub Actions

The plugin template includes a [GitHub Actions](https://github.com/features/actions) workflow to test and publish your plugin. You can extend it by adding any additional testing or deployment steps.

#### Publish to Maven Central
The template includes a Gradle task that will publish the plugin to Maven Central. You need a Maven Central account in order to publish your plugin.

You only need to configure the `gradle.properties` to have all required properties:

```yaml
sonatypeUsername=
sonatypePassword=
signing.keyId=
signing.password=
signing.secretKeyRingFile=

```


There is a pre-configured GitHub Actions workflow in the `.github/workflows/main.yml` file that you can customize to your need:
::collapse{title="Example"}
```yaml
# Publish
- name: Publish package to Sonatype
  if: github.ref == 'refs/heads/master'
  env:
    ORG_GRADLE_PROJECT_sonatypeUsername: ${{ secrets.SONATYPE_USER }}
    ORG_GRADLE_PROJECT_sonatypePassword: ${{ secrets.SONATYPE_PASSWORD }}
    SONATYPE_GPG_KEYID: ${{ secrets.SONATYPE_GPG_KEYID }}
    SONATYPE_GPG_PASSWORD: ${{ secrets.SONATYPE_GPG_PASSWORD }}
    SONATYPE_GPG_FILE: ${{ secrets.SONATYPE_GPG_FILE }}
  run: |
    echo "signing.keyId=${SONATYPE_GPG_KEYID}" > ~/.gradle/gradle.properties
    echo "signing.password=${SONATYPE_GPG_PASSWORD}" >> ~/.gradle/gradle.properties
    echo "signing.secretKeyRingFile=${HOME}/.gradle/secring.gpg" >> ~/.gradle/gradle.properties
    echo ${SONATYPE_GPG_FILE} | base64 -d > ~/.gradle/secring.gpg
    ./gradlew publishToSonatype

# Release
- name: Release package to Maven Central
  if: startsWith(github.ref, 'refs/tags/v')
  env:
    ORG_GRADLE_PROJECT_sonatypeUsername: ${{ secrets.SONATYPE_USER }}
    ORG_GRADLE_PROJECT_sonatypePassword: ${{ secrets.SONATYPE_PASSWORD }}
    SONATYPE_GPG_KEYID: ${{ secrets.SONATYPE_GPG_KEYID }}
    SONATYPE_GPG_PASSWORD: ${{ secrets.SONATYPE_GPG_PASSWORD }}
    SONATYPE_GPG_FILE: ${{ secrets.SONATYPE_GPG_FILE }}
  run: |
    echo "signing.keyId=${SONATYPE_GPG_KEYID}" > ~/.gradle/gradle.properties
    echo "signing.password=${SONATYPE_GPG_PASSWORD}" >> ~/.gradle/gradle.properties
    echo "signing.secretKeyRingFile=${HOME}/.gradle/secring.gpg" >> ~/.gradle/gradle.properties
    echo ${SONATYPE_GPG_FILE} | base64 -d > ~/.gradle/secring.gpg
    ./gradlew publishToSonatype closeAndReleaseSonatypeStagingRepository
```

::
