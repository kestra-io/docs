---
title: Main components
icon: /docs/icons/architecture.svg
---

Technical overview of Kestra’s main components: internal storage, queue, repository, and plugins.

Kestra relies on the following internal components:

- **Internal storage**: stores flow data such as task outputs and flow inputs.
- **Queue**: enables internal communication between Kestra server components.
- **Repository**: persists flows, templates, executions, logs, and all other internal objects.
- **Plugins**: extend Kestra’s core with additional task and trigger types, storage implementations, and data transformations.

Each component has multiple implementations depending on deployment architecture. Some require additional plugins.

## Internal storage

The **internal storage** is a dedicated system that handles files of any size during flow executions. It manages both inputs and outputs, enabling scalable file sharing between tasks.

### Purpose

Internal storage is used to:
- Save files generated during a [flow’s execution](../04.workflow-components/03.execution.md) and pass them between tasks via [outputs](../04.workflow-components/06.outputs.md).
- Automatically persist [flow inputs](../04.workflow-components/05.inputs.md) of type `FILE`.
- Provide download links for stored files in the **Outputs** tab of an execution.

Files can be retrieved in the execution context using `{{ outputs.task_id.output_attribute }}` (often the `uri` property). Kestra fetches the file automatically when referenced.

Execution metadata — including storage file paths — is recorded in the **repository**.

### Storage types

By default, Kestra uses **local storage**, which stores files on the host filesystem. This option is simple but not scalable and is usually not recommended for production (unless for standalone deployments).

:::alert{type="warning"}
Local storage behavior differs between standalone and distributed deployments:
- ✅ **Standalone**: Local storage with persistent volumes is OK
- ❌ **Distributed with ReadWriteOnce**: NOT recommended for distributed services
- ✅ **Distributed with ReadWriteMany**: OK for distributed services (rarely available)
- ❌ **Host storage sharing**: NOT recommended — difficult to achieve reliably

When `ReadWriteMany` is unavailable, use cloud storage (S3, GCS, Azure) or distributed object storage (MinIO, Ceph, SeaweedFS, Garage).
:::

Scalable alternatives are available as plugins:

- [Storage MinIO](https://github.com/kestra-io/storage-minio) — supports [MinIO](https://min.io/), [AWS S3](https://aws.amazon.com/s3/), and other S3-compatible systems.
- [Storage GCS](https://github.com/kestra-io/storage-gcs) — for [Google Cloud Storage](https://cloud.google.com/storage).
- [Storage Azure](https://github.com/kestra-io/storage-azure) — for [Azure Blob Storage](https://azure.microsoft.com/en-us/services/storage/blobs/).

For details, see [Internal storage configuration](../configuration/index.md#internal-storage-configuration).

## Queue

The **queue** is used internally for communication between Kestra’s server components. Each repository type has a matching queue implementation:

- **In-memory queue** — must be used with the in-memory repository.
- **Database queue** — must be used with the database repository.
- **Kafka queue** — must be used with the Elasticsearch repository.  
  **Only available in the [Enterprise Edition](../06.enterprise/01.overview/01.enterprise-edition.md).**

## Repository

The **repository** persists all internal objects, including flows, executions, logs, and templates. Each repository type must be paired with its corresponding queue:

- **In-memory repository** — must be used with the in-memory queue.
- **Database repository** — must be used with the database queue.
- **Elasticsearch repository** — must be used with the Kafka queue.  
  **Only available in the [Enterprise Edition](../06.enterprise/01.overview/01.enterprise-edition.md).**

## Plugins

Kestra’s core only provides basic functionality. A [plugin ecosystem](/plugins) extends the platform with:

- New task and trigger types.
- Alternative implementations of core components (e.g., storage backends).
- Integrations with external systems and data transformation utilities.

A wide range of plugins is already available, and the ecosystem continues to expand.
